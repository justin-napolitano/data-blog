{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/neo4j_integration/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Justin's Data Blog"}},"markdownRemark":{"id":"e6eb87b5-8ec8-5ad2-923d-971a6aa024ae","excerpt":"Introduction In a previous post, I detailed the process of crawling the Library of Congress API to generate json files that could be intergrated into you DB ofâ€¦","html":"<h2>Introduction</h2>\n<p>In a previous <a href=\"https://blog.jnapolitano.io/loc_crawler/\">post</a>, I detailed the process of crawling the Library of Congress API to generate json files that could be intergrated into you DB of choice.</p>\n<p>In this discussion, we will integrate JSON data into a Neo4j graph database.</p>\n<h2>Overview</h2>\n<p>The process is fairly straightforward.  The most difficult part is wrangling your json data into the right format for integration.</p>\n<p>The main function first instantiates the database config informormation.  It then gets the cwd from a context manager.  We then import the files to be integrated.  A master subject table is created to record only unique subjects to avoid duplicates.  Finally, a json pipeline extracts the data from json, transforms it to integrate into neo4j, and finally we upload using the neomodels api.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    neo_applified <span class=\"token operator\">=</span> instantiate_neo_model_api<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    cwd <span class=\"token operator\">=</span> get_cwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    file_list <span class=\"token operator\">=</span> get_files<span class=\"token punctuation\">(</span>cwd <span class=\"token operator\">=</span> cwd<span class=\"token punctuation\">)</span>\n    master_subject_table <span class=\"token operator\">=</span> create_master_subject_table<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    json_pipeline<span class=\"token punctuation\">(</span>file_list<span class=\"token operator\">=</span>file_list<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token operator\">=</span>master_subject_table<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Instantiate Neo Model Api</h2>\n<p>I extended the neo model api with a few helper functions.  The repo is found at <a href=\"https://github.com/justin-napolitano/neo4jAPI\">https://github.com/justin-napolitano/neo4jAPI</a>.</p>\n<p>You can also review the snapshot below.</p>\n<p>We will be calling the initation function to set the config information, update, create Case, and Create Subject classes during this review.</p>\n<p>create subject calls the custom subject class and returns an object that can later be integrated into the db with the .save() function.</p>\n<p>Create case does exactly the same.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> dataclasses <span class=\"token keyword\">import</span> dataclass\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> date\n<span class=\"token keyword\">from</span> shelve <span class=\"token keyword\">import</span> Shelf\n<span class=\"token keyword\">from</span> neomodel <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">,</span> StructuredNode<span class=\"token punctuation\">,</span> StringProperty<span class=\"token punctuation\">,</span> IntegerProperty<span class=\"token punctuation\">,</span>\n    UniqueIdProperty<span class=\"token punctuation\">,</span> RelationshipTo<span class=\"token punctuation\">,</span> BooleanProperty<span class=\"token punctuation\">,</span> EmailProperty<span class=\"token punctuation\">,</span> Relationship<span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> pprint <span class=\"token keyword\">import</span> pprint\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">neoAPI</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>uri<span class=\"token punctuation\">,</span>user<span class=\"token punctuation\">,</span>psw<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>db_init <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>instantiate_neo_model_session<span class=\"token punctuation\">(</span>uri<span class=\"token punctuation\">,</span>user<span class=\"token punctuation\">,</span>psw<span class=\"token punctuation\">)</span>    \n        \n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">instantiate_neo_model_session</span><span class=\"token punctuation\">(</span>uri<span class=\"token punctuation\">,</span>user<span class=\"token punctuation\">,</span>psw<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        \n        <span class=\"token comment\">#config.DATABASE_URL = 'neo4j+s://{}:{}@{}'.format(user, psw, uri)</span>\n        config<span class=\"token punctuation\">.</span>DATABASE_URL <span class=\"token operator\">=</span><span class=\"token string\">'bolt://neo4j:beautiful@localhost:7687'</span>\n        <span class=\"token comment\">#config.DATABASE_URL = uri</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">standard_query</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        results<span class=\"token punctuation\">,</span> meta <span class=\"token operator\">=</span> db<span class=\"token punctuation\">.</span>cypher_query<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> params<span class=\"token punctuation\">)</span>\n        people <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>Person<span class=\"token punctuation\">.</span>inflate<span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> results<span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_case_node</span><span class=\"token punctuation\">(</span>date<span class=\"token punctuation\">,</span> dates<span class=\"token punctuation\">,</span> group<span class=\"token punctuation\">,</span>name<span class=\"token punctuation\">,</span> pdf<span class=\"token punctuation\">,</span> shelf_id<span class=\"token punctuation\">,</span> subject<span class=\"token punctuation\">,</span> title<span class=\"token punctuation\">,</span> url<span class=\"token punctuation\">,</span> subject_relationship <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Case<span class=\"token punctuation\">(</span>date<span class=\"token operator\">=</span>date<span class=\"token punctuation\">,</span> dates<span class=\"token operator\">=</span>dates<span class=\"token punctuation\">,</span> group<span class=\"token operator\">=</span>group<span class=\"token punctuation\">,</span>name<span class=\"token operator\">=</span>name<span class=\"token punctuation\">,</span> pdf<span class=\"token operator\">=</span>pdf<span class=\"token punctuation\">,</span> shelf_id<span class=\"token operator\">=</span>shelf_id<span class=\"token punctuation\">,</span> subject<span class=\"token operator\">=</span>subject<span class=\"token punctuation\">,</span> title<span class=\"token operator\">=</span>title<span class=\"token punctuation\">,</span> url<span class=\"token operator\">=</span>url<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_city_node</span><span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> City<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">)</span>\n        \n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_country_node</span><span class=\"token punctuation\">(</span>code<span class=\"token punctuation\">,</span>name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Country<span class=\"token punctuation\">(</span>code <span class=\"token operator\">=</span> code<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_state_node</span><span class=\"token punctuation\">(</span>code<span class=\"token punctuation\">,</span>name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> State<span class=\"token punctuation\">(</span>code <span class=\"token operator\">=</span> code<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_realtor_search_url_node</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Realtor_Search_URL<span class=\"token punctuation\">(</span>url <span class=\"token operator\">=</span> url<span class=\"token punctuation\">,</span> is_root <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> is_sibling <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> is_parent<span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_child <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> searched <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_root_node</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'realtor.com'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Root<span class=\"token punctuation\">(</span>is_root <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">,</span>is_parent <span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_sibling <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_child <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> url <span class=\"token operator\">=</span> url<span class=\"token punctuation\">)</span>\n        uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_child_node</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'realtor.com'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Child<span class=\"token punctuation\">(</span>is_root <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">,</span>is_parent <span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_sibling <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_child <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> url <span class=\"token operator\">=</span> url<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_parent_node</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'realtor.com'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Parent<span class=\"token punctuation\">(</span>is_root <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">,</span>is_parent <span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_sibling <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_child <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> url <span class=\"token operator\">=</span> url<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_sibling_node</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'realtor.com'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Sibling<span class=\"token punctuation\">(</span>is_root <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">,</span>is_parent <span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_sibling <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> is_child <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> url <span class=\"token operator\">=</span> url<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_relationship</span><span class=\"token punctuation\">(</span>source<span class=\"token punctuation\">,</span>target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n      \n        \n        rel <span class=\"token operator\">=</span> source<span class=\"token punctuation\">.</span>connect<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> rel\n\n        <span class=\"token comment\">#print(\"{}\"+\".connect\" + \"{}\".format(source,target))</span>\n        \n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_subject_node</span><span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> Subject<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">update</span><span class=\"token punctuation\">(</span>obj<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">with</span> db<span class=\"token punctuation\">.</span>transaction<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> obj<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Subject</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uuid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Case</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    date <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    dates <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    group <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    pdf <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> \n    shelf_id <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    subject <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#primary_topic = StringProperty(unique_index=True, required=True)</span>\n    title <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    url <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    subject_relationship <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Subject\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_SUBJECT\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Processed</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">NotProcessed</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    \n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">City</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    state <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'State'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'IS_STATE_OF'</span><span class=\"token punctuation\">)</span>\n    country <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Country'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'IS_COUNTRY_OF'</span><span class=\"token punctuation\">)</span>\n    \n    \n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Country</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    code <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    \n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">State</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    code <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    country <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Country'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'IS_COUNTRY_OF'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Root</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    is_root <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_parent <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_sibling <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_child <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    url <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    processed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Processed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    NotProcessed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"NotProcessed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NOT_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    sibling <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Sibling\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_SIBLING\"</span><span class=\"token punctuation\">)</span>\n    child <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Child\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_CHILD\"</span><span class=\"token punctuation\">)</span>\n    parent <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Parent\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_PARENT\"</span><span class=\"token punctuation\">)</span>\n    root <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_ROOT\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Child</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    is_root <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_parent <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_sibling <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_child <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    processed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Processed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    NotProcessed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"NotProcessed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NOT_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    sibling <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Sibling\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_SIBLING\"</span><span class=\"token punctuation\">)</span>\n    child <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Child\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_CHILD\"</span><span class=\"token punctuation\">)</span>\n    parent <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Parent\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_PARENT\"</span><span class=\"token punctuation\">)</span>\n    root <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_ROOT\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Parent</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    is_root <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_parent <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_sibling <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_child <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    processed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Processed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    NotProcessed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"NotProcessed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NOT_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    sibling <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Sibling\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_SIBLING\"</span><span class=\"token punctuation\">)</span>\n    child <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Child\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_CHILD\"</span><span class=\"token punctuation\">)</span>\n    parent <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Parent\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_PARENT\"</span><span class=\"token punctuation\">)</span>\n    root <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_ROOT\"</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Sibling</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    is_root <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_parent <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_sibling <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_child <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    processed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Processed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    NotProcessed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"NotProcessed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NOT_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    sibling <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Sibling\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_SIBLING\"</span><span class=\"token punctuation\">)</span>\n    child <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Child\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_CHILD\"</span><span class=\"token punctuation\">)</span>\n    parent <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Parent\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_PARENT\"</span><span class=\"token punctuation\">)</span>\n    root <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_ROOT\"</span><span class=\"token punctuation\">)</span>\n    \n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Realtor_com</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    is_realtor_com <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Realtor_Search_URL</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    url <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    searched <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_root <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_child <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_parent <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    is_sibling <span class=\"token operator\">=</span> BooleanProperty<span class=\"token punctuation\">(</span>unique_index <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#state = Relationship('State', 'OF')</span>\n    state <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'State'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'IS_STATE_OF'</span><span class=\"token punctuation\">)</span>\n    city <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'City'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'IS_CITY_OF'</span><span class=\"token punctuation\">)</span>\n    root <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Root'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'IS_ROOT'</span><span class=\"token punctuation\">)</span>\n    child <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Child'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"IS_CHILD\"</span><span class=\"token punctuation\">)</span>\n    parent <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Parent'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_PARENT\"</span><span class=\"token punctuation\">)</span>\n    sibling <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Sibling'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_SIBLING\"</span><span class=\"token punctuation\">)</span>\n    realtor_com <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">'Realtor_com'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_REALTOR.COM_URL\"</span><span class=\"token punctuation\">)</span>\n    processed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Processed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n    NotProcessed <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"NotProcessed\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"NOT_PROCESSED\"</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Person</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    full_name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>required <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    email <span class=\"token operator\">=</span> EmailProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Get Files</h2>\n<p>The get_files function returns a list of files within the input directory.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_files</span><span class=\"token punctuation\">(</span>cwd <span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>getcwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> input_directory <span class=\"token operator\">=</span> <span class=\"token string\">'input'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    \n    path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>sep<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>cwd<span class=\"token punctuation\">,</span>input_directory<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    file_list<span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>f <span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> glob<span class=\"token punctuation\">.</span>glob<span class=\"token punctuation\">(</span>path <span class=\"token operator\">+</span> <span class=\"token string\">\"**/*.json\"</span><span class=\"token punctuation\">,</span> recursive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n  \n    <span class=\"token keyword\">return</span> file_list\n</code></pre></div>\n<h2>Create Master Subject File</h2>\n<p>Create maseter subject table generates an empty dataframe that will record every unique subject experienced in the data.</p>\n<p>I will improve upon this later, by uploading a master file that will be saved following each modification.  This would enable resuming the process following an error or fault.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_master_subject_table</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    table <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    table<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    table<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    table<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">(</span>table<span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h2>Json Pipeline function</h2>\n<p>The json pipeline function is the runner for the etl job.  It loads each file into dataframe, manipulates the data accordingly, and updates the neo4j database.</p>\n<p>When I refactor the code, I will most likely create an object that calls static functions to generate then desired output.</p>\n<p>I may also seperate the case, subject, and relationship pipeline into seperate classes in order to avoid shadowing functions within functions.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">json_pipeline</span><span class=\"token punctuation\">(</span>file_list<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    case_counter <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> file_list<span class=\"token punctuation\">:</span>\n        \n        data <span class=\"token operator\">=</span> load_json_data<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token operator\">=</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span>\n        data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'results'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token comment\">#pprint(data[0])</span>\n        \n        <span class=\"token comment\">#filtered_data = filter_json_data(json_data = data, filter = filter)</span>\n\n        <span class=\"token comment\"># Creating the case nodes transaction nodes and df</span>\n        data <span class=\"token operator\">=</span> clean_json_data<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> stringify_json_values<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> pandify_case_data<span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> nodify_case_data<span class=\"token punctuation\">(</span>case_data <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># Creating the subject nodes transaction nodes and df</span>\n        subject_list <span class=\"token operator\">=</span> slice_subject_data<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n        subject_list <span class=\"token operator\">=</span> identify_unique_subjects<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n        subject_lookup_table <span class=\"token operator\">=</span> create_subject_lookup_table<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n        master_subject_table <span class=\"token operator\">=</span> integrate_to_master_table<span class=\"token punctuation\">(</span>subject_lookup_table<span class=\"token punctuation\">,</span>master_subject_table<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(master_subject_table.duplicated())</span>\n        case_counter <span class=\"token operator\">=</span> case_counter <span class=\"token operator\">+</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span>\n\n        master_subject_table <span class=\"token operator\">=</span> nodify_subjects<span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\">#pprint(case_data)</span>\n        <span class=\"token comment\">#pprint(master_subject_table['transaction'])</span>\n        <span class=\"token comment\">#lets save data to the database</span>\n\n        master_subject_table <span class=\"token operator\">=</span> submit_subjects_to_db<span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> submit_cases_to_db<span class=\"token punctuation\">(</span>case_data <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Create Relationships</span>\n\n        relationship_list<span class=\"token operator\">=</span> create_relationship_table<span class=\"token punctuation\">(</span>case_data<span class=\"token operator\">=</span>case_data<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token operator\">=</span>master_subject_table<span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Case Pipeline</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Creating the case nodes transaction nodes and df</span>\ndata <span class=\"token operator\">=</span> clean_json_data<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\ncase_data <span class=\"token operator\">=</span> stringify_json_values<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\ncase_data <span class=\"token operator\">=</span> pandify_case_data<span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span>\ncase_data <span class=\"token operator\">=</span> nodify_case_data<span class=\"token punctuation\">(</span>case_data <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">)</span></code></pre></div>\n<p>To create the case nodes four functions are called.</p>\n<h4>Clean Json Data</h4>\n<p>The first is clean_json_data which is actually unnecessary.  The only operation that is required is moving the pdf froma list to a dicktionary key.  It should and will be refactored.  As it stands now, I am leaving iut as an artifact of a previous workflow.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">def</span> <span class=\"token function\">clean_json_data</span><span class=\"token punctuation\">(</span>filtered_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Select the keys that I want from the dictionary</span>\n    <span class=\"token comment\"># filter appropriatly into a df </span>\n    <span class=\"token comment\"># write df to file</span>\n    <span class=\"token comment\">#print(type(filtered_data))</span>\n    <span class=\"token comment\">#pprint(filtered_data)</span>\n    <span class=\"token keyword\">for</span> data <span class=\"token keyword\">in</span> filtered_data<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token comment\">#creat a dictionary of columns and values for each row.  Combine them all into a df when we are done</span>\n        <span class=\"token comment\"># each dictionary must be a row.... which makes perfect sense, but they can not be nested... </span>\n        item <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'item'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        resources <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'resources'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        index <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'index'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        language <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'language'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        online_format<span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'online_format'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        original_format <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'original_format'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        kind <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'type'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        image_url <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'image_url'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        hassegments <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'hassegments'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        extract_timestamp <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'extract_timestamp'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        timestampe <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        mimetype<span class=\"token operator\">=</span>data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'mime_type'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            pdf <span class=\"token operator\">=</span> resources<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'pdf'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span> \n            pdf <span class=\"token operator\">=</span> <span class=\"token string\">\"noPdf\"</span>\n        data<span class=\"token punctuation\">[</span><span class=\"token string\">\"pdf\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pdf\n        data<span class=\"token punctuation\">[</span><span class=\"token string\">'search_index'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> index\n    </code></pre></div>\n<h4>Stringify Json Data</h4>\n<p>The Second is Stringify_json_data.  The imporatance of this function is that it creates strings from lists in order to properly integrate into the neo4j databse.  Iterables are permitted, however they can not be searched.  For my use case, I decided to create csv strings instead that can later be parsed if necessary.</p>\n<p>This function also moves the subject list to a dedicated key in the dictionary.  This is important because it is used to generate the subject tables.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">stringify_json_values</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> <span class=\"token builtin\">dict</span> <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n        subject_list <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> key <span class=\"token keyword\">in</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">:</span>\n                tmp_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n                <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    item <span class=\"token operator\">=</span> item<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"-\"</span><span class=\"token punctuation\">)</span>\n                    tmp_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n                <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> tmp_list\n\n                <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\",\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject_list'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> subject_list\n\n                \n    <span class=\"token keyword\">return</span> data</code></pre></div>\n<h4>Pandify Case Data</h4>\n<p>The next function creates a pandas dataframe from a list of dictionaries.  Thankfully this is easy to accommplish.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">pandify_case_data</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#case_df = pd.concat(data, sort=False)</span>\n    df<span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    <span class=\"token keyword\">return</span> df</code></pre></div>\n<h4>Nodify Case Data</h4>\n<p>Nodify creates transaction objects that can be saved to the neo4j databse.  I call the neomodel api to generate the results and save them into a dataframe that is used to apply the upload with a lambda function.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">nodify_case_data</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#non_submitted_nodes = case_data[case_data.notna()]</span>\n    non_submitted_nodes <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">[</span>case_data<span class=\"token punctuation\">.</span>notna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    case_nodes <span class=\"token operator\">=</span> non_submitted_nodes<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_case_node<span class=\"token punctuation\">(</span>date <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dates<span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'dates'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>group <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'group'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span>x<span class=\"token punctuation\">[</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> pdf<span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'pdf'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> shelf_id <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'shelf_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> subject<span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> title <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> url <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'url'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> subject_relationship<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> case_nodes\n    <span class=\"token keyword\">return</span> case_data\n</code></pre></div>\n<h3>The Subject Pipeline</h3>\n<p>The subject pipeline slices the subject data from the current search result page.</p>\n<p>It then identifies the unique subjects</p>\n<p>The subject_lookup_table is a dataframe containing the subjects returned by subject list.  They are unique only to the result page.</p>\n<p>The master_subject_table is then updated by the integrate_to_master_table function that identifes new subjects to integrate into the master table.</p>\n<p>finally, the nodify subject function creates transaction objects to be uploaded to the neo4j db.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">  <span class=\"token comment\"># Creating the subject nodes transaction nodes and df</span>\n    subject_list <span class=\"token operator\">=</span> slice_subject_data<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n    subject_list <span class=\"token operator\">=</span> identify_unique_subjects<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n    subject_lookup_table <span class=\"token operator\">=</span> create_subject_lookup_table<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n    master_subject_table <span class=\"token operator\">=</span> integrate_to_master_table<span class=\"token punctuation\">(</span>subject_lookup_table<span class=\"token punctuation\">,</span>master_subject_table<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#pprint(master_subject_table.duplicated())</span>\n\n    master_subject_table <span class=\"token operator\">=</span> nodify_subjects<span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span>\n    </code></pre></div>\n<h4>slice_subject_data</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">slice_subject_data</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    subject_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> <span class=\"token keyword\">case</span> <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n        subject_list <span class=\"token operator\">=</span> subject_list <span class=\"token operator\">+</span> <span class=\"token keyword\">case</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject_list'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\">#pprint(subject_list)</span>\n    <span class=\"token keyword\">return</span> subject_list</code></pre></div>\n<h4>Identify Unique Subjects</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">identify_unique_subjects</span><span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    \n    <span class=\"token comment\"># insert the list to the set</span>\n    list_set <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># convert the set to the list</span>\n    unique_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>list_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> unique_list\n</code></pre></div>\n<h4>Create Subject Lookup Table</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">create_subject_lookup_table</span><span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    lookup_table <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    lookup_table<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    lookup_table<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    <span class=\"token keyword\">return</span> lookup_table</code></pre></div>\n<h4>Nodify Subject</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">nodify_subjects</span><span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    non_submitted_nodes <span class=\"token operator\">=</span> master_subject_table<span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">.</span>isna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#df[df.isna().any(axis=1)]</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_subject_node<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    master_subject_table<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>non_submitted_nodes<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> master_subject_table</code></pre></div>\n<h3>Uploading Case and Subject data</h3>\n<p>With the transaction object dataframes created, we can then update the data to the database.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">master_subject_table <span class=\"token operator\">=</span> submit_subjects_to_db<span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span>\ncase_data <span class=\"token operator\">=</span> submit_cases_to_db<span class=\"token punctuation\">(</span>case_data <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">)</span></code></pre></div>\n<h4>Submit Subjects</h4>\n<p>This function selects the subject nodes from the master table that have not been uploaded to the neo4j database.</p>\n<p>It identifies na in the submitted collumn in order to slice non-submitted nodes.</p>\n<p>If that table can be created we upload all of the df with the update function from the neoapi.  It simply calls the db and calls save() on the object.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">submit_subjects_to_db</span><span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#unsubmitted = master_subject_table[master_subject_table.notna()]</span>\n    <span class=\"token comment\">#pprint(master_subject_table)</span>\n    <span class=\"token comment\">#non_submitted_nodes=master_subject_table[[master_subject_table['submitted'] == np.nan]]</span>\n    non_submitted_nodes <span class=\"token operator\">=</span> master_subject_table<span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    <span class=\"token keyword\">if</span> non_submitted_nodes<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">:</span>   \n        <span class=\"token keyword\">return</span> master_subject_table\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n         <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n        non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n    \n    <span class=\"token comment\">#test = non_submitted_nodes.iloc[32]['transaction']</span>\n    <span class=\"token comment\">#return_obj = neo.neoAPI.update(test)</span>\n        master_subject_table<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>non_submitted_nodes<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(master_subject_table)</span>\n        <span class=\"token keyword\">return</span> master_subject_table</code></pre></div>\n<h4>Submit Cases</h4>\n<p>Initially i had copy and pasted the subject submission function. I realized that the checks were unnecessary.   I am assuming that each result is unique.  Therefore, every case is uploaded.  If it proves that there are duplicates in the database, the neo4j cypher language would permit me to prune those duplicate edges.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">submit_cases_to_db</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#unsubmitted = master_subject_table[master_subject_table.notna()]</span>\n\n        <span class=\"token comment\">### in theory none of the cases wouldhave been submitted becasue i am pulling them from file.  There is no need to check.. Just submit</span>\n    <span class=\"token comment\">#non_submitted_nodes = case_data[case_data['submitted'].isna()].copy()</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    <span class=\"token comment\">##pprint(non_submitted_nodes)</span>\n    <span class=\"token comment\">#if non_submitted_nodes.empty:</span>\n    <span class=\"token comment\">#    return case_data</span>\n    <span class=\"token comment\">#else:</span>\n    case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#Assume all are submitted..</span>\n    case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n    <span class=\"token comment\">#test = non_submitted_nodes.iloc[32]['transaction']</span>\n    <span class=\"token comment\">#return_obj = neo.neoAPI.update(test)</span>\n    <span class=\"token comment\">#case_data.update(non_submitted_nodes)</span>\n    <span class=\"token keyword\">return</span> case_data</code></pre></div>\n<h3>Submit the Relationships</h3>\n<p>The final step is to relate the cases to the subject nodes.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">relationship_list= create_relationship_table(case_data=case_data, master_subject_table=master_subject_table)</code></pre></div>\n<p>This is accomplished by calling the relationship function declared in the Case class declared in the neomodel api.</p>\n<p>View the reference below:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Case</span><span class=\"token punctuation\">(</span>StructuredNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uid <span class=\"token operator\">=</span> UniqueIdProperty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    date <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    dates <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    group <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    name <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    pdf <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> \n    shelf_id <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    subject <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#primary_topic = StringProperty(unique_index=True, required=True)</span>\n    title <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    url <span class=\"token operator\">=</span> StringProperty<span class=\"token punctuation\">(</span>unique_index<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    subject_relationship <span class=\"token operator\">=</span> Relationship<span class=\"token punctuation\">(</span><span class=\"token string\">\"Subject\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"IS_SUBJECT\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h4>Create Relationship Table</h4>\n<p>To create the relationships the case_data and the master_subject_table are necessary.</p>\n<p>for every case a relationship is created to every subject within its subject list.</p>\n<p>It is important to note, that in order for this function to work correctly, the cases and subjects must first be submitted to the database.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_relationship_table</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#pprint(case_data[])</span>\n        <span class=\"token comment\">#test = master_subject_table['subject']</span>\n        <span class=\"token comment\"># select </span>\n    relationship_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        unique_dataframe <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isin<span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'subject_list'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(unique_dataframe)</span>\n        <span class=\"token keyword\">for</span> subject_row <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>unique_dataframe<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">case</span> <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span>\n            subject <span class=\"token operator\">=</span> unique_dataframe<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>subject_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span>\n            <span class=\"token comment\">#create relationship</span>\n            <span class=\"token comment\">#pprint(case)</span>\n            <span class=\"token comment\">#pprint(subject)</span>\n            relationship <span class=\"token operator\">=</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span><span class=\"token keyword\">case</span><span class=\"token punctuation\">.</span>subject_relationship<span class=\"token punctuation\">,</span>subject<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#pprint(relationship)</span>\n            relationship_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>relationship<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> relationship_list</code></pre></div>\n<h2>Putting Everything Together</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token comment\">#realtor_graph.py</span>\n\n\n<span class=\"token comment\">#from neo4j_connect_2 import NeoSandboxApp</span>\n<span class=\"token comment\">#import neo4j_connect_2 as neo</span>\n<span class=\"token comment\">#import GoogleServices as google</span>\n<span class=\"token comment\">#from pyspark.sql import SparkSession</span>\n<span class=\"token comment\">#from pyspark.sql.functions import struct</span>\n<span class=\"token keyword\">from</span> cgitb <span class=\"token keyword\">import</span> lookup\n<span class=\"token keyword\">import</span> code\n<span class=\"token keyword\">from</span> dbm <span class=\"token keyword\">import</span> dumb\n<span class=\"token keyword\">from</span> doctest <span class=\"token keyword\">import</span> master\n<span class=\"token keyword\">from</span> hmac <span class=\"token keyword\">import</span> trans_36\n<span class=\"token keyword\">import</span> mimetypes\n<span class=\"token keyword\">from</span> platform <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> pprint <span class=\"token keyword\">import</span> pprint\n<span class=\"token keyword\">from</span> pty <span class=\"token keyword\">import</span> master_open\n<span class=\"token keyword\">from</span> re <span class=\"token keyword\">import</span> sub\n<span class=\"token keyword\">from</span> unittest<span class=\"token punctuation\">.</span>util <span class=\"token keyword\">import</span> unorderable_list_difference\n<span class=\"token keyword\">from</span> urllib<span class=\"token punctuation\">.</span>parse <span class=\"token keyword\">import</span> non_hierarchical\n<span class=\"token keyword\">from</span> neomodel <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">,</span> StructuredNode<span class=\"token punctuation\">,</span> StringProperty<span class=\"token punctuation\">,</span> IntegerProperty<span class=\"token punctuation\">,</span>\n    UniqueIdProperty<span class=\"token punctuation\">,</span> RelationshipTo<span class=\"token punctuation\">,</span> BooleanProperty<span class=\"token punctuation\">,</span> EmailProperty<span class=\"token punctuation\">,</span> Relationship<span class=\"token punctuation\">,</span>db<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token comment\">#import NeoNodes as nn</span>\n<span class=\"token comment\">#import GoogleServices</span>\n<span class=\"token keyword\">import</span> neo4jClasses\n<span class=\"token comment\">#import sparkAPI as spark</span>\n<span class=\"token keyword\">import</span> neoModelAPI <span class=\"token keyword\">as</span> neo\n<span class=\"token keyword\">import</span> glob\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> json\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token comment\">#from neoModelAPI import NeoNodes as nn</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DataUploadFunctions</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">upload_df</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#df.apply(lambda x: pprint(str(x) + str(type(x))))</span>\n        \n        node_list <span class=\"token operator\">=</span>  df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(node_list)</span>\n        <span class=\"token keyword\">return</span>  node_list\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">map_to_df</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df1<span class=\"token punctuation\">,</span>df2<span class=\"token punctuation\">,</span>lookup_value <span class=\"token punctuation\">:</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> lookup_key<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        df1<span class=\"token punctuation\">[</span>lookup_value<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df1<span class=\"token punctuation\">[</span>lookup_key<span class=\"token punctuation\">]</span>\n        <span class=\"token comment\">#pprint(df1.columns)</span>\n        <span class=\"token comment\">#pprint(df1)</span>\n        \n        val  <span class=\"token operator\">=</span> df1<span class=\"token punctuation\">[</span>lookup_value<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>df2<span class=\"token punctuation\">[</span>lookup_key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>  df2<span class=\"token punctuation\">[</span>lookup_value<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> val\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">set_relationships</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>source_node<span class=\"token punctuation\">,</span> target_node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(self.df.columns)</span>\n        <span class=\"token comment\">#pprint(source_node)</span>\n        rel <span class=\"token operator\">=</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span>source <span class=\"token operator\">=</span> source_node <span class=\"token punctuation\">,</span>target <span class=\"token operator\">=</span> target_node<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> rel\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DataPipelineFunctions</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">write_df_to_csv</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">,</span>path<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cwd <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getcwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>sep<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>cwd<span class=\"token punctuation\">,</span>path<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span><span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n            df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> path\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_city_nodes</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        city_nodes <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'city_name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_city_node<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> city_nodes\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_url_nodes</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        url_nodes <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'root_realtor_url'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_realtor_search_url_node<span class=\"token punctuation\">(</span>url<span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> url_nodes\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_root_nodes</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        root_nodes <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'root_realtor_url'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_root_node<span class=\"token punctuation\">(</span>url<span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> root_nodes\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_country_nodes</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        country_nodes <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_country_node<span class=\"token punctuation\">(</span>code <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>country_code<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>country_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>axis <span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> country_nodes\n        \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">return_unique_country_df</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        df <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>drop_duplicates<span class=\"token punctuation\">(</span>subset<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'country_name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        df<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>difference<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'country_node'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'state_node'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'country_name'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'country_code'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'state_name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(df)</span>\n        <span class=\"token keyword\">return</span> df\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_state_nodes</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        state_nodes <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_state_node<span class=\"token punctuation\">(</span>code <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>state_code<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>state_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>axis <span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> state_nodes    \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">return_unique_state_df</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        df <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>drop_duplicates<span class=\"token punctuation\">(</span>subset<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'state_name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        df<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">.</span>difference<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'state_node'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'country_node'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'country_code'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'state_name'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'country_name'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'state_code'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(df)</span>\n\n        <span class=\"token keyword\">return</span> df\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">rename_columns</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">,</span> mapper <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'city'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'city_name'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'state'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'state_code'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'realtor_url'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'root_realtor_url'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> df<span class=\"token punctuation\">.</span>rename<span class=\"token punctuation\">(</span>columns <span class=\"token operator\">=</span> mapper<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">add_country_code</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>country_code <span class=\"token operator\">=</span> <span class=\"token string\">\"USA\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> country_code\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">add_country_name</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>country_name <span class=\"token operator\">=</span> <span class=\"token string\">\"United States of America\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> country_name\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">upload_df</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#df.apply(lambda x: pprint(str(x) + str(type(x))))</span>\n        \n        node_list <span class=\"token operator\">=</span>  df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        pprint<span class=\"token punctuation\">(</span>node_list<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span>  node_list\n        <span class=\"token comment\">#df['server_node'] =  node_list</span>\n        <span class=\"token comment\">#pprint(df)</span>\n        \n        \n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">set_url_relationships</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(self.df.columns)</span>\n        update_list <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span>source <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>url_node<span class=\"token punctuation\">.</span>city<span class=\"token punctuation\">,</span>target <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>city_node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        pprint<span class=\"token punctuation\">(</span>update_list<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> update_list\n        <span class=\"token comment\">#rel = self.df.url.connect(self.df.city)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">set_city_relationships</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(self.df.columns)</span>\n        update_list <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span>source <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>city_node<span class=\"token punctuation\">.</span>country<span class=\"token punctuation\">,</span>target <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>country_node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        update_list <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span>source <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>city_node<span class=\"token punctuation\">.</span>state<span class=\"token punctuation\">,</span>target <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>state_node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        pprint<span class=\"token punctuation\">(</span>update_list<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#rel = self.df.url.connect(self.df.city)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">set_state_relationships</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(self.df.columns)</span>\n        neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span>source <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>unique_state_nodes<span class=\"token punctuation\">.</span>state_node<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>country<span class=\"token punctuation\">,</span>target <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>unique_state_nodes<span class=\"token punctuation\">.</span>country_node<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#update_list = self.unique_state_nodes.apply(lambda x: neo.neoAPI.create_relationship(source = x.state_node.country,target = x.country_node.name), axis=1)</span>\n        <span class=\"token comment\">#pprint(update_list)</span>\n        <span class=\"token comment\">#rel = self.df.url.connect(self.df.city)</span>\n\n\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">group_by_state</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        grouped <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span>by <span class=\"token operator\">=</span> <span class=\"token string\">\"state_name\"</span><span class=\"token punctuation\">)</span>\n        \n    <span class=\"token keyword\">def</span> <span class=\"token function\">load_data_to_pandas_df</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_path <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> file_path <span class=\"token operator\">!=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n\n            <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span> <span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span>\n                df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_json<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> df\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">nodify_city_column</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'city_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'city'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_city_node<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        \n        \n        <span class=\"token comment\">#pprint(df.city_nodes)</span>\n\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">nodify_states_column</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        unique_states <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span>drop_duplicates<span class=\"token punctuation\">(</span>subset<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'state'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(state_dict)</span>\n\n        unique_states<span class=\"token punctuation\">[</span><span class=\"token string\">'state_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> unique_states<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_state_node<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>state_name<span class=\"token punctuation\">,</span> code <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>state<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(unique_states)</span>\n        <span class=\"token comment\">#self.df['state_nodes'] = unique_states['state_nodes'] where unique_states[state_name] = self.df_stateName</span>\n        self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">\"state_node\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'state_name'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token comment\">#self.df['state_node'] =</span>\n        <span class=\"token comment\">#pprint(self.df['state_name'].map(unique_states))</span>\n        self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'state_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'state_node'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>unique_states<span class=\"token punctuation\">.</span>state_name<span class=\"token punctuation\">,</span>  unique_states<span class=\"token punctuation\">.</span>state_node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(self.df)</span>\n\n        \n     \n        <span class=\"token comment\">#mask = dfd['a'].str.startswith('o')</span>\n        \n        \n        <span class=\"token comment\">#self.df['state_nodes'] = self.df.apply(lambda x: neo.create_state_node(name = x.state_name, code = x.state) if x not in states_dict else states_dict[x], axis=1)</span>\n        \n    <span class=\"token keyword\">def</span> <span class=\"token function\">nodify_url_column</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'url_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'realtor_url'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_url_node<span class=\"token punctuation\">(</span>url <span class=\"token operator\">=</span> x<span class=\"token punctuation\">,</span> searched<span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n    \n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_cwd</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    cwd <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getcwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> cwd\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_files</span><span class=\"token punctuation\">(</span>cwd <span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>getcwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> input_directory <span class=\"token operator\">=</span> <span class=\"token string\">'input'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    \n    path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>sep<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>cwd<span class=\"token punctuation\">,</span>input_directory<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    file_list<span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>f <span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> glob<span class=\"token punctuation\">.</span>glob<span class=\"token punctuation\">(</span>path <span class=\"token operator\">+</span> <span class=\"token string\">\"**/*.json\"</span><span class=\"token punctuation\">,</span> recursive<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n  \n    <span class=\"token keyword\">return</span> file_list\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">instantiate_neo_model_api</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    uri <span class=\"token operator\">=</span> <span class=\"token string\">\"7a92f171.databases.neo4j.io\"</span>\n    user <span class=\"token operator\">=</span> <span class=\"token string\">\"neo4j\"</span>\n    psw <span class=\"token operator\">=</span> <span class=\"token string\">'RF4Gr2IJTNhHlW6HOrLDqz_I2E2Upyh7o8paTwfnCxg'</span>\n    <span class=\"token keyword\">return</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>instantiate_neo_model_session<span class=\"token punctuation\">(</span>uri<span class=\"token operator\">=</span>uri<span class=\"token punctuation\">,</span>user<span class=\"token operator\">=</span>user<span class=\"token punctuation\">,</span>psw<span class=\"token operator\">=</span>psw<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">prepare_data_pipeline</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    pipeline_functions <span class=\"token operator\">=</span> DataPipelineFunctions<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    master_df <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>load_data_to_pandas_df<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    master_df<span class=\"token punctuation\">[</span><span class=\"token string\">'country_name'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>add_country_name<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    master_df<span class=\"token punctuation\">[</span><span class=\"token string\">'country_code'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>add_country_code<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    master_df <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>rename_columns<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">)</span>\n    master_df<span class=\"token punctuation\">[</span><span class=\"token string\">'city_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>create_city_nodes<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">)</span>\n    master_df<span class=\"token punctuation\">[</span><span class=\"token string\">'url_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>create_url_nodes<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">)</span>\n    master_df<span class=\"token punctuation\">[</span><span class=\"token string\">'root_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>create_root_nodes<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">)</span>\n\n    \n    master_df_path <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>write_df_to_csv<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">,</span><span class=\"token string\">'master_df.csv'</span><span class=\"token punctuation\">)</span>\n\n    \n\n    \n    state_df <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>return_unique_state_df<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">)</span>\n    state_df<span class=\"token punctuation\">[</span><span class=\"token string\">'state_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>create_state_nodes<span class=\"token punctuation\">(</span>state_df<span class=\"token punctuation\">)</span>\n    state_df_path <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>write_df_to_csv<span class=\"token punctuation\">(</span>state_df<span class=\"token punctuation\">,</span><span class=\"token string\">'state_df.csv'</span><span class=\"token punctuation\">)</span>\n    \n\n    country_df <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>return_unique_country_df<span class=\"token punctuation\">(</span>master_df<span class=\"token punctuation\">)</span>\n    country_df<span class=\"token punctuation\">[</span><span class=\"token string\">'country_node'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>create_country_nodes<span class=\"token punctuation\">(</span>country_df<span class=\"token punctuation\">)</span>\n    country_df_path <span class=\"token operator\">=</span> pipeline_functions<span class=\"token punctuation\">.</span>write_df_to_csv<span class=\"token punctuation\">(</span>country_df<span class=\"token punctuation\">,</span><span class=\"token string\">'country.csv'</span><span class=\"token punctuation\">)</span>\n\n\n    \n\n\n\n    <span class=\"token comment\">#upload nodes</span>\n    \n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"master_df\"</span> <span class=\"token punctuation\">:</span> master_df<span class=\"token punctuation\">,</span> <span class=\"token string\">'state_df'</span> <span class=\"token punctuation\">:</span> state_df<span class=\"token punctuation\">,</span> <span class=\"token string\">'country_df'</span><span class=\"token punctuation\">:</span> country_df<span class=\"token punctuation\">}</span>\n\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">load_json_data</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    f <span class=\"token operator\">=</span> <span class=\"token builtin\">open</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"r\"</span><span class=\"token punctuation\">)</span>\n  \n    <span class=\"token comment\"># Reading from file</span>\n    data <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>loads<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> data\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">json_pipeline</span><span class=\"token punctuation\">(</span>file_list<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    case_counter <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> file_list<span class=\"token punctuation\">:</span>\n        \n        data <span class=\"token operator\">=</span> load_json_data<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token operator\">=</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span>\n        data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'results'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token comment\">#pprint(data[0])</span>\n        \n        <span class=\"token comment\">#filtered_data = filter_json_data(json_data = data, filter = filter)</span>\n\n        <span class=\"token comment\"># Creating the case nodes transaction nodes and df</span>\n        data <span class=\"token operator\">=</span> clean_json_data<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> stringify_json_values<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> pandify_case_data<span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> nodify_case_data<span class=\"token punctuation\">(</span>case_data <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># Creating the subject nodes transaction nodes and df</span>\n        subject_list <span class=\"token operator\">=</span> slice_subject_data<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n        subject_list <span class=\"token operator\">=</span> identify_unique_subjects<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n        subject_lookup_table <span class=\"token operator\">=</span> create_subject_lookup_table<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n        master_subject_table <span class=\"token operator\">=</span> integrate_to_master_table<span class=\"token punctuation\">(</span>subject_lookup_table<span class=\"token punctuation\">,</span>master_subject_table<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(master_subject_table.duplicated())</span>\n        case_counter <span class=\"token operator\">=</span> case_counter <span class=\"token operator\">+</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span>\n\n        master_subject_table <span class=\"token operator\">=</span> nodify_subjects<span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\">#pprint(case_data)</span>\n        <span class=\"token comment\">#pprint(master_subject_table['transaction'])</span>\n        <span class=\"token comment\">#lets save data to the database</span>\n\n        master_subject_table <span class=\"token operator\">=</span> submit_subjects_to_db<span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span>\n        case_data <span class=\"token operator\">=</span> submit_cases_to_db<span class=\"token punctuation\">(</span>case_data <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Create Relationships</span>\n\n        relationship_list<span class=\"token operator\">=</span> create_relationship_table<span class=\"token punctuation\">(</span>case_data<span class=\"token operator\">=</span>case_data<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token operator\">=</span>master_subject_table<span class=\"token punctuation\">)</span>\n    \n\n\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">submit_cases_to_db</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#unsubmitted = master_subject_table[master_subject_table.notna()]</span>\n\n        <span class=\"token comment\">### in theory none of the cases wouldhave been submitted becasue i am pulling them from file.  There is no need to check.. Just submit</span>\n    <span class=\"token comment\">#non_submitted_nodes = case_data[case_data['submitted'].isna()].copy()</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    <span class=\"token comment\">##pprint(non_submitted_nodes)</span>\n    <span class=\"token comment\">#if non_submitted_nodes.empty:</span>\n    <span class=\"token comment\">#    return case_data</span>\n    <span class=\"token comment\">#else:</span>\n    case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#Assume all are submitted..</span>\n    case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n    <span class=\"token comment\">#test = non_submitted_nodes.iloc[32]['transaction']</span>\n    <span class=\"token comment\">#return_obj = neo.neoAPI.update(test)</span>\n    <span class=\"token comment\">#case_data.update(non_submitted_nodes)</span>\n    <span class=\"token keyword\">return</span> case_data\n\n    <span class=\"token comment\">#Relationships must need to be created following saving to the df</span>\n    <span class=\"token comment\">#relationships = create_relationship_table(case_data, master_subject_table)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">submit_subjects_to_db</span><span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#unsubmitted = master_subject_table[master_subject_table.notna()]</span>\n    <span class=\"token comment\">#pprint(master_subject_table)</span>\n    <span class=\"token comment\">#non_submitted_nodes=master_subject_table[[master_subject_table['submitted'] == np.nan]]</span>\n    non_submitted_nodes <span class=\"token operator\">=</span> master_subject_table<span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    <span class=\"token keyword\">if</span> non_submitted_nodes<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">:</span>   \n        <span class=\"token keyword\">return</span> master_subject_table\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n         <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n        non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n    \n    <span class=\"token comment\">#test = non_submitted_nodes.iloc[32]['transaction']</span>\n    <span class=\"token comment\">#return_obj = neo.neoAPI.update(test)</span>\n        master_subject_table<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>non_submitted_nodes<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(master_subject_table)</span>\n        <span class=\"token keyword\">return</span> master_subject_table\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">tester</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token string\">\"Hello Dolly\"</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_relationship_table</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#pprint(case_data[])</span>\n        <span class=\"token comment\">#test = master_subject_table['subject']</span>\n        <span class=\"token comment\"># select </span>\n    relationship_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        unique_dataframe <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isin<span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'subject_list'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(unique_dataframe)</span>\n        <span class=\"token keyword\">for</span> subject_row <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>unique_dataframe<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">case</span> <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span>\n            subject <span class=\"token operator\">=</span> unique_dataframe<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>subject_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span>\n            <span class=\"token comment\">#create relationship</span>\n            <span class=\"token comment\">#pprint(case)</span>\n            <span class=\"token comment\">#pprint(subject)</span>\n            relationship <span class=\"token operator\">=</span> neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_relationship<span class=\"token punctuation\">(</span><span class=\"token keyword\">case</span><span class=\"token punctuation\">.</span>subject_relationship<span class=\"token punctuation\">,</span>subject<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#pprint(relationship)</span>\n            relationship_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>relationship<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> relationship_list\n\n\n\n\n        \n    <span class=\"token comment\">#create relationship between the case and each uid in the unique_data_frame_transaction_list </span>\n    pprint<span class=\"token punctuation\">(</span>unique_dataframe<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token comment\">## Creating the realation table</span>\n\n    <span class=\"token comment\"># Thoughts</span>\n    <span class=\"token comment\"># pass subject and case table</span>\n    <span class=\"token comment\"># case_subject list collumn</span>\n    <span class=\"token comment\"># where that list is in the master table</span>\n        <span class=\"token comment\">#return  the subjects </span>\n    <span class=\"token comment\"># make a connection to between each subject and the case in the returned tableuid in the table</span>\n    <span class=\"token comment\"># return a transaction list </span>\n    <span class=\"token comment\"># with the list commit a transaction for eachn </span>\n    <span class=\"token comment\">#</span>\n\n    <span class=\"token comment\">#case_data= filter_case_data(data)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">nodify_case_data</span><span class=\"token punctuation\">(</span>case_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#non_submitted_nodes = case_data[case_data.notna()]</span>\n    non_submitted_nodes <span class=\"token operator\">=</span> case_data<span class=\"token punctuation\">[</span>case_data<span class=\"token punctuation\">.</span>notna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    case_nodes <span class=\"token operator\">=</span> non_submitted_nodes<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_case_node<span class=\"token punctuation\">(</span>date <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dates<span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'dates'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>group <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'group'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span>x<span class=\"token punctuation\">[</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> pdf<span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'pdf'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> shelf_id <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'shelf_id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> subject<span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> title <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> url <span class=\"token operator\">=</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'url'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> subject_relationship<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    case_data<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> case_nodes\n    <span class=\"token keyword\">return</span> case_data\n\n\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">filter_case_data</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    pprint<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">nodify_subjects</span><span class=\"token punctuation\">(</span>master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    non_submitted_nodes <span class=\"token operator\">=</span> master_subject_table<span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">.</span>isna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#df[df.isna().any(axis=1)]</span>\n    <span class=\"token comment\">#pprint(non_submitted_nodes)</span>\n    non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> non_submitted_nodes<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x <span class=\"token punctuation\">:</span>neo<span class=\"token punctuation\">.</span>neoAPI<span class=\"token punctuation\">.</span>create_subject_node<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    master_subject_table<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>non_submitted_nodes<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> master_subject_table\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">integrate_to_master_table</span><span class=\"token punctuation\">(</span>subject_lookup_table<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#check_if subject in list is in subject of the table</span>\n    <span class=\"token comment\"># if so drop it from the temp table</span>\n    <span class=\"token comment\"># append what is left to the master table </span>\n    <span class=\"token comment\">#pprint(subject_lookup_table)</span>\n    test <span class=\"token operator\">=</span> master_subject_table<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span>\n    unique_dataframe <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>subject_lookup_table<span class=\"token punctuation\">[</span><span class=\"token operator\">~</span>subject_lookup_table<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isin<span class=\"token punctuation\">(</span>test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#pprint(unique_dataframe)</span>\n    <span class=\"token comment\">#duplicate_list = (master_subject_table[~master_subject_table['subject'].isin(subject_lookup_table['subject'])])</span>\n    master_subject_table <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>master_subject_table<span class=\"token punctuation\">,</span>unique_dataframe<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#master_subject_table.update(unique_dataframe)</span>\n    master_subject_table<span class=\"token punctuation\">.</span>reset_index<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> drop<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#pprint(master_subject_table)</span>\n    <span class=\"token comment\">#pprint(master_subject_table.duplicated())</span>\n    <span class=\"token keyword\">return</span> master_subject_table\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_subject_lookup_table</span><span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    lookup_table <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    lookup_table<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    lookup_table<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    <span class=\"token keyword\">return</span> lookup_table\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">identify_unique_subjects</span><span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    \n    <span class=\"token comment\"># insert the list to the set</span>\n    list_set <span class=\"token operator\">=</span> <span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>subject_list<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># convert the set to the list</span>\n    unique_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>list_set<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> unique_list\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">slice_subject_data</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    subject_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> <span class=\"token keyword\">case</span> <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n        subject_list <span class=\"token operator\">=</span> subject_list <span class=\"token operator\">+</span> <span class=\"token keyword\">case</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject_list'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\">#pprint(subject_list)</span>\n    <span class=\"token keyword\">return</span> subject_list\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">pandify_case_data</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#case_df = pd.concat(data, sort=False)</span>\n    df<span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    <span class=\"token keyword\">return</span> df\n        \n<span class=\"token keyword\">def</span> <span class=\"token function\">stringify_json_values</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> <span class=\"token builtin\">dict</span> <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n        subject_list <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> key <span class=\"token keyword\">in</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">:</span>\n                tmp_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n                <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    item <span class=\"token operator\">=</span> item<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"-\"</span><span class=\"token punctuation\">)</span>\n                    tmp_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n                <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> tmp_list\n\n                <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\",\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token builtin\">dict</span><span class=\"token punctuation\">[</span><span class=\"token string\">'subject_list'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> subject_list\n\n                \n    <span class=\"token keyword\">return</span> data\n                \n\n    <span class=\"token comment\">#pprint(data)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">clean_json_data</span><span class=\"token punctuation\">(</span>filtered_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Select the keys that I want from the dictionary</span>\n    <span class=\"token comment\"># filter appropriatly into a df </span>\n    <span class=\"token comment\"># write df to file</span>\n    <span class=\"token comment\">#print(type(filtered_data))</span>\n    <span class=\"token comment\">#pprint(filtered_data)</span>\n    <span class=\"token keyword\">for</span> data <span class=\"token keyword\">in</span> filtered_data<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token comment\">#creat a dictionary of columns and values for each row.  Combine them all into a df when we are done</span>\n        <span class=\"token comment\"># each dictionary must be a row.... which makes perfect sense, but they can not be nested... </span>\n        item <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'item'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        resources <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'resources'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        index <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'index'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        language <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'language'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        online_format<span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'online_format'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        original_format <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'original_format'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        kind <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'type'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        image_url <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'image_url'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        hassegments <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'hassegments'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        extract_timestamp <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'extract_timestamp'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        timestampe <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'timestamp'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        mimetype<span class=\"token operator\">=</span>data<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token string\">'mime_type'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            pdf <span class=\"token operator\">=</span> resources<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'pdf'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span> \n            pdf <span class=\"token operator\">=</span> <span class=\"token string\">\"noPdf\"</span>\n        data<span class=\"token punctuation\">[</span><span class=\"token string\">\"pdf\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pdf\n        data<span class=\"token punctuation\">[</span><span class=\"token string\">'search_index'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> index\n    \n\n\n    <span class=\"token comment\"># convert to strings maybe move into another function to be called.  Actually will definitely move to a nother function </span>\n\n    <span class=\"token keyword\">return</span> filtered_data\n    <span class=\"token comment\">#uid = UniqueIdProperty()</span>\n    <span class=\"token comment\">##date = date</span>\n    <span class=\"token comment\">#dates = dates</span>\n    <span class=\"token comment\">#group = group</span>\n    <span class=\"token comment\">#id = id </span>\n    <span class=\"token comment\">#pdf = pdf </span>\n    <span class=\"token comment\">#shelf_id = shelf_id</span>\n    <span class=\"token comment\">#subject = subject</span>\n    <span class=\"token comment\">#primary_topic = primary_topic</span>\n    <span class=\"token comment\">#title = title</span>\n    <span class=\"token comment\">#url = url</span>\n    <span class=\"token comment\">#description = description</span>\n    <span class=\"token comment\">#source_collection = source_collection</span>\n\n\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">filter_json_data</span><span class=\"token punctuation\">(</span>json_data<span class=\"token punctuation\">,</span> <span class=\"token builtin\">filter</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Using dict()</span>\n    <span class=\"token comment\"># Extracting specific keys from dictionary</span>\n\n    <span class=\"token builtin\">filter</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'contributor'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dates'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'digitized'</span><span class=\"token punctuation\">]</span>\n    res <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">,</span> json_data<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> <span class=\"token builtin\">filter</span> <span class=\"token keyword\">if</span> k <span class=\"token keyword\">in</span> json_data<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> res\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_master_subject_table</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    table <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    table<span class=\"token punctuation\">[</span><span class=\"token string\">'subject'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    table<span class=\"token punctuation\">[</span><span class=\"token string\">'transaction'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    table<span class=\"token punctuation\">[</span><span class=\"token string\">'submitted'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>nan\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">(</span>table<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    neo_applified <span class=\"token operator\">=</span> instantiate_neo_model_api<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    cwd <span class=\"token operator\">=</span> get_cwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    file_list <span class=\"token operator\">=</span> get_files<span class=\"token punctuation\">(</span>cwd <span class=\"token operator\">=</span> cwd<span class=\"token punctuation\">)</span>\n    master_subject_table <span class=\"token operator\">=</span> create_master_subject_table<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    json_pipeline<span class=\"token punctuation\">(</span>file_list<span class=\"token operator\">=</span>file_list<span class=\"token punctuation\">,</span> master_subject_table<span class=\"token operator\">=</span>master_subject_table<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\">#neo_sandbox_app = instantiate_neo_sandbox_app()</span>\n    <span class=\"token comment\">#google_creds = load_google_creds()</span>\n    <span class=\"token comment\">#sheets_app = instantiate_sheets_app(google_creds.credentials)</span>\n    <span class=\"token comment\">#drive_app = instantiate_drive_app(google_creds.credentials)</span>\n    <span class=\"token comment\">#googleAPI = instantiate_google_API()</span>\n    <span class=\"token comment\">#sparkAPI = instantiate_spark_API()</span>\n    <span class=\"token comment\">#neoAPI = NeoAPI()</span>\n    <span class=\"token comment\">#nodified_df = pandas_functions.nodify_dataframe()</span>\n    <span class=\"token comment\">#test()</span>\n    <span class=\"token comment\">#google_api = googleServices.GoogleAPI()</span>\n    <span class=\"token comment\">###neo_model_api = instantiate_neo_model_api()</span>\n    <span class=\"token comment\">###df_pipeline_dictionary = prepare_data_pipeline()</span>\n    <span class=\"token comment\">#final_df_dictionary = upload_data_pipeline_to_neo(df_pipeline_dictionary)</span>\n    <span class=\"token comment\">#for k,v in final_df_dictionary.items():</span>\n    <span class=\"token comment\">#    cwd = os.getcwd()</span>\n    <span class=\"token comment\">#    path = str(k) +\"Final\"</span>\n    <span class=\"token comment\">#    path = os.sep.join([cwd,path])</span>\n\n     <span class=\"token comment\">#   with open(path, \"w\") as file:</span>\n     <span class=\"token comment\">#       v.to_csv(path, index=False)</span>\n\n    <span class=\"token comment\">#prepared_dfs = prepare_pandas_df()</span>\n    <span class=\"token comment\">#pprint(prepared_df)</span>\n    <span class=\"token comment\">#upload_df_to_db(df = prepared_df, neo_model_api = neo_model_api)</span>\n</code></pre></div>","frontmatter":{"title":"Integrating JSON data to your Neo4j Stack","date":"May 16, 2022","description":"Integrate JSON data from a rest API into your Neo4j Stack","imageAlt":"Justin Napolitano","author":"Justin Napolitano","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAAChUlEQVQ4y2WTW3PaSBSE/f//xr6kKlW7lbhcu2uDCba4mpsAI4lLJLAEEmgkjUYS4elLIeKkSB5OzTyc09N9uufGshacTifyPKcoCo7HY1l5liFlQqZSUimRMi0rTS8lpfxxJsTuAOX1UMmeG9Occzp9Q6UpeV4Qi5C53mfcqbOcDrG9A1Ip/H2EvxekcUQcil/AcczXLw8s/v+M8FxuTMMqmcVxjFIZ241Nu3pL5dMH9FYNe7Um2PklIyFiXupdelWNKBQopcq5dk2j/m+Vnbe9AB6PBUmSkCqFCEMsvYfefGQ5mzB+btO+q7B3XeJE0npso9W6RFFMlmWkMsZo3THT/kEE7jWgUil+mNAaOwT+jlhEjLUOzdt7WpUGq9kcbeRg2gHPow19w8U/RDQGM6rtMbvgcA14liVTyTYQGHZAFEWIULA25zTu7lnoU9buDtt54/llxmTh4bgBWuUjldu/2Hmb3ySnKVmmSilnRyMRlaCut2MymjAxVvQnFpZpoOsmwW5PpiSvepfJsMlh7/8yRZ2Z+RHPX/p4jk0UhhgvPcyBznK1oVNr0PzvgV53gG1/pVFtYIxeSwJ58Y3ieCo9+AmYppLDQTDuDpnPbRzXp/PYYKR18L0t3fsatY9/06w3sVY2vvuGOISlqrO695X9IbnIMyKpmI5tek9D+jWNYLvFNi309oDxYMhTo0Nn4rAXSZnf95Cfqwz2lSlSkimF82pjTxcsRhM2iyXedou5WmM6PvWuxXC6wj/EZTLe5y4MzTnF8Xj1yvmuMkWaFwz7UzoPT0ytN3qvTslod4gJRVTuXf7O0DAsVFb8AXiJUIp7jslyjYhiwvjSo372Xf/r88/5DmrPtszs6JbsAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/acfac79560b8c0f033301fb165d0ca3b/8d197/post-image.png","srcSet":"/static/acfac79560b8c0f033301fb165d0ca3b/d734b/post-image.png 750w,\n/static/acfac79560b8c0f033301fb165d0ca3b/8d197/post-image.png 1000w","sizes":"100vw"},"sources":[{"srcSet":"/static/acfac79560b8c0f033301fb165d0ca3b/c0126/post-image.avif 750w,\n/static/acfac79560b8c0f033301fb165d0ca3b/c296e/post-image.avif 1000w","type":"image/avif","sizes":"100vw"},{"srcSet":"/static/acfac79560b8c0f033301fb165d0ca3b/59596/post-image.webp 750w,\n/static/acfac79560b8c0f033301fb165d0ca3b/904ec/post-image.webp 1000w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.625}}}}},"previous":{"fields":{"slug":"/loc_crawler/"},"frontmatter":{"title":"Crawling the Library of Congress API"}},"next":{"fields":{"slug":"/constitution_to_neo/"},"frontmatter":{"title":"Integrating The US Constitution into Neo4j for ML Trickery "}}},"pageContext":{"id":"e6eb87b5-8ec8-5ad2-923d-971a6aa024ae","previousPostId":"c37f105a-dd41-5f18-9dd3-df41400006f2","nextPostId":"6392a68f-8513-540d-aeec-9993aeb06092"}},
    "staticQueryHashes": ["2841359383","3257411868"]}