{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/loc_crawler/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Justin's Data Blog"}},"markdownRemark":{"id":"c37f105a-dd41-5f18-9dd3-df41400006f2","excerpt":"Crawling the Library of Congress API Introduction The United States Library of Congress maintains a rest api for developers to crawl their collections.  It isâ€¦","html":"<h1>Crawling the Library of Congress API</h1>\n<h2>Introduction</h2>\n<p>The United States Library of Congress maintains a rest api for developers to crawl their collections.  It is an open source tool that anyone can access in order to conduct research. Check out the documenation at <a href=\"https://libraryofcongress.github.io/data-exploration/\">https://libraryofcongress.github.io/data-exploration/</a>.</p>\n<h2>Creating a crawler</h2>\n<p>I took the approach of writing a generator that produces a search result page object that can be operated upon with each iteration.</p>\n<p>The first step is to create a search result page object.</p>\n<p>The code below documents the search_result page.  It contains a number of helper functions to convert the nodes within the result to json or graphml.  The code can also be used to generate a networkx in memory graph.</p>\n<h3>The Search Result Object</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">search_results_page</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>base_url <span class=\"token operator\">=</span> <span class=\"token string\">\"https://www.loc.gov/collections\"</span><span class=\"token punctuation\">,</span>collection <span class=\"token operator\">=</span> <span class=\"token string\">\"united-states-reports\"</span><span class=\"token punctuation\">,</span>json_parameter <span class=\"token operator\">=</span> <span class=\"token string\">\"fo=json\"</span><span class=\"token punctuation\">,</span>results_per_page <span class=\"token operator\">=</span> <span class=\"token string\">\"c=79\"</span><span class=\"token punctuation\">,</span>query_param <span class=\"token operator\">=</span> <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">,</span>page_param <span class=\"token operator\">=</span><span class=\"token string\">\"sp=\"</span><span class=\"token punctuation\">,</span>page_num <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(num_columns)</span>\n        self<span class=\"token punctuation\">.</span>search_url <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>create_search_url<span class=\"token punctuation\">(</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>query_param<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">,</span>page_num<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>response <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>request_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>response_json <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>response_to_json<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#self.soup_html = self.html_parse()</span>\n        self<span class=\"token punctuation\">.</span>next_url <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>get_next_url<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>page_num <span class=\"token operator\">=</span> page_num\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_json</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span>file_num <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span><span class=\"token string\">\".json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>output_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> outfile<span class=\"token punctuation\">:</span>\n            json<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">,</span> outfile<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_pandas</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        df <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>to_pandas_edgelist<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_csv</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span>file_num <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span><span class=\"token string\">\".csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        df <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>to_pandas<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>output_name<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">write_graphml</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span> file_num<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span> <span class=\"token string\">\".graphml\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        nx<span class=\"token punctuation\">.</span>write_graphml<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">,</span> output_name<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">write_to_file</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>data <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span>file_num <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span> <span class=\"token string\">\".json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>output_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> outfile<span class=\"token punctuation\">:</span>\n            json<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> outfile<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">node_gen_2</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> root <span class=\"token operator\">=</span><span class=\"token string\">'result'</span><span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> edge_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#root = root </span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">and</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> node_list<span class=\"token punctuation\">:</span>\n                    graph<span class=\"token punctuation\">.</span>add_node<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> k<span class=\"token punctuation\">)</span>\n                    <span class=\"token comment\">#node_list.append((k, {'type' : k}))</span>\n                    <span class=\"token comment\">#(1, 2, color='red', weight=0.84, size=300)\\</span>\n                    graph<span class=\"token punctuation\">.</span>add_edge<span class=\"token punctuation\">(</span>root<span class=\"token punctuation\">,</span>k<span class=\"token punctuation\">,</span> relationship <span class=\"token operator\">=</span> <span class=\"token string\">\"of\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"root\"</span><span class=\"token punctuation\">)</span>\n                    <span class=\"token comment\">#edge_list.append((root , k, {\"relationship\" : \"of\"}, {\"type\" : 'root'}))</span>\n                <span class=\"token comment\">#pprint('passing_value')</span>\n                <span class=\"token comment\">#save k</span>\n                previous_k <span class=\"token operator\">=</span> k\n                previous_edge <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>root <span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>node_gen_2<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">elif</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n                <span class=\"token comment\">#pprint('passing_data')</span>\n\n                self<span class=\"token punctuation\">.</span>node_gen_2<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span>previous_k <span class=\"token operator\">=</span> previous_k<span class=\"token punctuation\">,</span> previous_edge<span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#create_edge to k</span>\n\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#this item is no longer a dictionary or list</span>\n            pprint<span class=\"token punctuation\">(</span><span class=\"token string\">'appending_data'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#create edge to k</span>\n            <span class=\"token keyword\">if</span> data <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n                graph<span class=\"token punctuation\">.</span>add_node<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span><span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#node_list.append((data, {\"type\" : data}))</span>\n                graph<span class=\"token punctuation\">.</span>add_edge<span class=\"token punctuation\">(</span>previous_k<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> relationship <span class=\"token operator\">=</span> <span class=\"token string\">\"is\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> previous_k<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#edge_list.append((previous_k ,data,{'relationship': \"is\"}, {'type' : data}))</span>\n                <span class=\"token comment\">#edge_list.append((root,data))</span>\n\n    <span class=\"token comment\">#flatten(hierarchak)_dict)</span>\n        <span class=\"token keyword\">return</span> graph \n\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">node_runner</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">,</span>graph<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        \n        node_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        edge_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#root = item['title']</span>\n            graph <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>node_gen_2<span class=\"token punctuation\">(</span>data <span class=\"token operator\">=</span> item<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(edge_list)</span>\n        <span class=\"token keyword\">return</span> graph\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">node_generator</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> root <span class=\"token operator\">=</span><span class=\"token string\">'title_testing'</span><span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> edge_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">and</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> node_list<span class=\"token punctuation\">:</span>\n                    node_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">)</span>\n                    edge_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>root <span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#pprint('passing_value')</span>\n                <span class=\"token comment\">#save k</span>\n                previous_k <span class=\"token operator\">=</span> k\n                previous_edge <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>root <span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>node_generator<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">elif</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n                <span class=\"token comment\">#pprint('passing_data')</span>\n\n                self<span class=\"token punctuation\">.</span>node_generator<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span>previous_k <span class=\"token operator\">=</span> previous_k<span class=\"token punctuation\">,</span> previous_edge<span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#create_edge to k</span>\n\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#this item is no longer a dictionary or list</span>\n            pprint<span class=\"token punctuation\">(</span><span class=\"token string\">'appending_data'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#create edge to k</span>\n            <span class=\"token keyword\">if</span> data <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n                node_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n                edge_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>previous_k <span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                edge_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>root<span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">#flatten(hierarchak)_dict)</span>\n        <span class=\"token keyword\">return</span> node_list<span class=\"token punctuation\">,</span> edge_list \n        <span class=\"token comment\">#self.json_graph = self.create_json_graph()</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_json_graph</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#graph = nx.Graph(self.response_json)</span>\n        graph <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>from_dict_of_dicts<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#graph = json_graph.node_link_graph(self.response_json)</span>\n        nx<span class=\"token punctuation\">.</span>draw<span class=\"token punctuation\">(</span>graph<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> graph\n        \n        <span class=\"token comment\">#self.node_list = self.node_generator`</span>\n\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_search_result_node</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     \n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>response_json_flat<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span>v <span class=\"token keyword\">in</span> item<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">:</span>\n                    column_string <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>colnum_string<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n                    self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>colnum_string<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_columns<span class=\"token punctuation\">)</span>\n                    self<span class=\"token punctuation\">.</span>num_columns <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">continue</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">append_to_data_list</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>rnge<span class=\"token punctuation\">,</span>d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token comment\">#rename to _data_list</span>\n        request_body <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'range'</span><span class=\"token punctuation\">:</span> rnge<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"majorDimension\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"COLUMNS\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"values\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>d<span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> request_body\n        <span class=\"token comment\">#data_list.append(request_body_tmp)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">map_column_to_range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>column_key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        \n        rnge <span class=\"token operator\">=</span> <span class=\"token string\">\"'Sheet1'\"</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"!\"</span> <span class=\"token operator\">+</span> column_key <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> rnge\n                \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">colnum_string</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>num_columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        string <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span>\n        <span class=\"token comment\">#pprint(\"conlum_string\")</span>\n        <span class=\"token comment\">#pprint(num_columns)</span>\n        <span class=\"token keyword\">while</span> num_columns <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            num_columns<span class=\"token punctuation\">,</span> remainder <span class=\"token operator\">=</span> <span class=\"token builtin\">divmod</span><span class=\"token punctuation\">(</span>num_columns <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">26</span><span class=\"token punctuation\">)</span>\n            string <span class=\"token operator\">=</span> <span class=\"token builtin\">chr</span><span class=\"token punctuation\">(</span><span class=\"token number\">65</span> <span class=\"token operator\">+</span> remainder<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> string\n            <span class=\"token comment\">#pprint(string)</span>\n        <span class=\"token keyword\">return</span> string\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">map_columns_to_lookup_table</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        <span class=\"token comment\">#print('first_map_columns_print')</span>\n        <span class=\"token comment\">#num_columns_tmp = self.num_columns</span>\n        <span class=\"token comment\">#pprint(num_columns_tmp)</span>\n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>response_json_flat<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> item<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                num_columns_tmp <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>num_columns\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">:</span>\n                    <span class=\"token comment\">#print('second_map_Columns_print')</span>\n                    <span class=\"token comment\">#pprint(num_columns_tmp)</span>\n                    self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>colnum_string<span class=\"token punctuation\">(</span>num_columns <span class=\"token operator\">=</span> num_columns_tmp<span class=\"token punctuation\">)</span>\n                    self<span class=\"token punctuation\">.</span>num_columns <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>num_columns <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n       \n                    <span class=\"token comment\">#append range to request... </span>\n                    <span class=\"token comment\">#append collumn to batch lookup</span>\n                \n\n                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">continue</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">column_request_list_generator</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        request_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span>v <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            rnge <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>map_column_to_range<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">)</span>\n            request_body <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>append_to_data_list<span class=\"token punctuation\">(</span>rnge<span class=\"token punctuation\">,</span>v<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#pprint(request_body)</span>\n            request_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>request_body<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> request_list\n\n\n\n\n\n        <span class=\"token comment\">#return column_lookup_table</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_next_url</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">[</span><span class=\"token string\">'pagination'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'next'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_search_url</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>query_param<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">,</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        url_sep <span class=\"token operator\">=</span><span class=\"token string\">\"/\"</span>\n        page_param <span class=\"token operator\">=</span> page_param <span class=\"token operator\">+</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        query <span class=\"token operator\">=</span> <span class=\"token string\">\"&amp;\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        query <span class=\"token operator\">=</span> query_param <span class=\"token operator\">+</span> query\n        search_url <span class=\"token operator\">=</span> url_sep<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>query<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(search_url)</span>\n        \n        <span class=\"token keyword\">return</span> search_url\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">say_hello</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        pprint<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>base_url<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">request_data</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        headers <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'User-Agent'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.11 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token string\">'Accept-Encoding'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'identity'</span>\n                <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>search_url<span class=\"token punctuation\">,</span>headers<span class=\"token operator\">=</span>headers<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">response_to_json</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>response<span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">html_parse</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        soup<span class=\"token operator\">=</span>BeautifulSoup<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">,</span><span class=\"token string\">'lxml'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(soup)</span>\n        <span class=\"token keyword\">return</span> soup\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">flatten_result</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        flat_result_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">[</span><span class=\"token string\">'results'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            flat_json <span class=\"token operator\">=</span> flatten<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n            flat_result_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>flat_json<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> flat_result_list\n</code></pre></div>\n<h2>The Generator</h2>\n<p>The generator yields a search result page if the pagination link included in the response is valid.</p>\n<p>Depending on your use case you could pass the page_num and collection you would like to crawl.</p>\n<p>The api is limited to 80 results per minute.  The sleep function limits calls to the desired rate.  The amount of results returned can be passed to the search result page_object.  Review the code above to see which values can be passed.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">search_result_generator</span><span class=\"token punctuation\">(</span>condition <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#column_lookup_table = {}</span>\n    <span class=\"token comment\">#pprint(num_columns)</span>\n    page_num <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    column_lookup_table <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">while</span> condition <span class=\"token operator\">==</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(num_columns)</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">61</span><span class=\"token punctuation\">)</span>\n        search_results_page_object <span class=\"token operator\">=</span> create_search_results_page_object<span class=\"token punctuation\">(</span>page_num <span class=\"token operator\">=</span> page_num<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> search_results_page_object<span class=\"token punctuation\">.</span>next_url <span class=\"token operator\">!=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            condition <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n            page_num <span class=\"token operator\">=</span> page_num <span class=\"token operator\">+</span> <span class=\"token number\">1</span>            \n            <span class=\"token keyword\">yield</span> <span class=\"token punctuation\">(</span>search_results_page_object<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            condition <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n            <span class=\"token keyword\">yield</span> <span class=\"token punctuation\">(</span>search_results_page_object<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>The Runner Function</h2>\n<p>To initiate the crawl simply run the algorithm below.  It writes each result page to json.</p>\n<p>As a follow up project, I will post how to integrate the data returned into a neo4j database.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> obj <span class=\"token keyword\">in</span> search_result_generator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>   \n        page_num <span class=\"token operator\">=</span> obj<span class=\"token punctuation\">.</span>page_num\n        <span class=\"token keyword\">with</span> cd<span class=\"token punctuation\">(</span><span class=\"token string\">\"output_2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#print('hahaha')</span>\n            obj<span class=\"token punctuation\">.</span>to_json<span class=\"token punctuation\">(</span>file_num <span class=\"token operator\">=</span> page_num<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#obj.write_graphml(file_num= page_num)</span>\n            <span class=\"token comment\">#obj.to_pandas()</span>\n            <span class=\"token comment\">#obj.write_to_file(data = obj.dict_of_dicts, file_num = page_num)</span>\n            <span class=\"token comment\">#obj.to_csv()</span>\n        write_last_page_num<span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"{} Search Results Crawled\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<h2>Putting Everything Together</h2>\n<p>The code below is the entire program as it stands.  There is built in functionality to upload the results to a google sheet if that is what you desire using an extension of the google api.   That code can be found at <a href=\"https://github.com/justin-napolitano/GoogleAPI\">https://github.com/justin-napolitano/GoogleAPI</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#library_of_congress_scraper.py</span>\n<span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> print_function\n<span class=\"token keyword\">from</span> bs4 <span class=\"token keyword\">import</span> BeautifulSoup\n<span class=\"token keyword\">import</span> requests\n<span class=\"token keyword\">import</span> lxml<span class=\"token punctuation\">.</span>etree <span class=\"token keyword\">as</span> etree\n<span class=\"token keyword\">import</span> xml<span class=\"token punctuation\">.</span>etree<span class=\"token punctuation\">.</span>ElementTree <span class=\"token keyword\">as</span> ET\n<span class=\"token keyword\">import</span> json\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> random\n<span class=\"token keyword\">import</span> math\n<span class=\"token keyword\">from</span> pprint <span class=\"token keyword\">import</span> pprint\n<span class=\"token comment\">#import load_vars as lv</span>\n<span class=\"token keyword\">import</span> html\n<span class=\"token keyword\">import</span> yaml\n<span class=\"token keyword\">from</span> yaml <span class=\"token keyword\">import</span> Loader<span class=\"token punctuation\">,</span> Dumper\n<span class=\"token keyword\">import</span> glob\n<span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> os<span class=\"token punctuation\">.</span>path\n<span class=\"token keyword\">from</span> googleapiclient<span class=\"token punctuation\">.</span>discovery <span class=\"token keyword\">import</span> build\n<span class=\"token keyword\">from</span> google_auth_oauthlib<span class=\"token punctuation\">.</span>flow <span class=\"token keyword\">import</span> InstalledAppFlow\n<span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>auth<span class=\"token punctuation\">.</span>transport<span class=\"token punctuation\">.</span>requests <span class=\"token keyword\">import</span> Request\n<span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>oauth2<span class=\"token punctuation\">.</span>credentials <span class=\"token keyword\">import</span> Credentials\n<span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>oauth2 <span class=\"token keyword\">import</span> service_account\n<span class=\"token keyword\">from</span> googleapiclient<span class=\"token punctuation\">.</span>http <span class=\"token keyword\">import</span> MediaIoBaseDownload<span class=\"token punctuation\">,</span> MediaFileUpload\n<span class=\"token keyword\">from</span> flatten_json <span class=\"token keyword\">import</span> flatten\n<span class=\"token keyword\">import</span> networkx <span class=\"token keyword\">as</span> nx\n<span class=\"token keyword\">import</span> matplotlib\n<span class=\"token keyword\">from</span> networkx<span class=\"token punctuation\">.</span>readwrite <span class=\"token keyword\">import</span> json_graph\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> tracemalloc\n<span class=\"token keyword\">import</span> os\n<span class=\"token comment\">#from ratelimiter import RateLimiter</span>\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">cd</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Context manager for changing the current working directory\"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> newPath<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>newPath <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>expanduser<span class=\"token punctuation\">(</span>newPath<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__enter__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>savedPath <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getcwd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        os<span class=\"token punctuation\">.</span>chdir<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>newPath<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__exit__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> etype<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">,</span> traceback<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        os<span class=\"token punctuation\">.</span>chdir<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>savedPath<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">search_results_page</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>base_url <span class=\"token operator\">=</span> <span class=\"token string\">\"https://www.loc.gov/collections\"</span><span class=\"token punctuation\">,</span>collection <span class=\"token operator\">=</span> <span class=\"token string\">\"united-states-reports\"</span><span class=\"token punctuation\">,</span>json_parameter <span class=\"token operator\">=</span> <span class=\"token string\">\"fo=json\"</span><span class=\"token punctuation\">,</span>results_per_page <span class=\"token operator\">=</span> <span class=\"token string\">\"c=79\"</span><span class=\"token punctuation\">,</span>query_param <span class=\"token operator\">=</span> <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">,</span>page_param <span class=\"token operator\">=</span><span class=\"token string\">\"sp=\"</span><span class=\"token punctuation\">,</span>page_num <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(num_columns)</span>\n        self<span class=\"token punctuation\">.</span>search_url <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>create_search_url<span class=\"token punctuation\">(</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>query_param<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">,</span>page_num<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>response <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>request_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>response_json <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>response_to_json<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#self.soup_html = self.html_parse()</span>\n        self<span class=\"token punctuation\">.</span>next_url <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>get_next_url<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>page_num <span class=\"token operator\">=</span> page_num\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_json</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span>file_num <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span><span class=\"token string\">\".json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>output_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> outfile<span class=\"token punctuation\">:</span>\n            json<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">,</span> outfile<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_pandas</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        df <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>to_pandas_edgelist<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">to_csv</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span>file_num <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span><span class=\"token string\">\".csv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        df <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>to_pandas<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        df<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span>output_name<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">write_graphml</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span> file_num<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span> <span class=\"token string\">\".graphml\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        nx<span class=\"token punctuation\">.</span>write_graphml<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">,</span> output_name<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">write_to_file</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>data <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> file_name <span class=\"token operator\">=</span> <span class=\"token string\">'result_'</span><span class=\"token punctuation\">,</span>file_num <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> extension <span class=\"token operator\">=</span> <span class=\"token string\">\".json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_name <span class=\"token operator\">=</span> file_name <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>file_num<span class=\"token punctuation\">)</span>\n        output_name <span class=\"token operator\">=</span> output_name <span class=\"token operator\">+</span> extension\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>output_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> outfile<span class=\"token punctuation\">:</span>\n            json<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> outfile<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">node_gen_2</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> root <span class=\"token operator\">=</span><span class=\"token string\">'result'</span><span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> edge_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#root = root </span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">and</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> node_list<span class=\"token punctuation\">:</span>\n                    graph<span class=\"token punctuation\">.</span>add_node<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> k<span class=\"token punctuation\">)</span>\n                    <span class=\"token comment\">#node_list.append((k, {'type' : k}))</span>\n                    <span class=\"token comment\">#(1, 2, color='red', weight=0.84, size=300)\\</span>\n                    graph<span class=\"token punctuation\">.</span>add_edge<span class=\"token punctuation\">(</span>root<span class=\"token punctuation\">,</span>k<span class=\"token punctuation\">,</span> relationship <span class=\"token operator\">=</span> <span class=\"token string\">\"of\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"root\"</span><span class=\"token punctuation\">)</span>\n                    <span class=\"token comment\">#edge_list.append((root , k, {\"relationship\" : \"of\"}, {\"type\" : 'root'}))</span>\n                <span class=\"token comment\">#pprint('passing_value')</span>\n                <span class=\"token comment\">#save k</span>\n                previous_k <span class=\"token operator\">=</span> k\n                previous_edge <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>root <span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>node_gen_2<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">elif</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n                <span class=\"token comment\">#pprint('passing_data')</span>\n\n                self<span class=\"token punctuation\">.</span>node_gen_2<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span>previous_k <span class=\"token operator\">=</span> previous_k<span class=\"token punctuation\">,</span> previous_edge<span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#create_edge to k</span>\n\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#this item is no longer a dictionary or list</span>\n            pprint<span class=\"token punctuation\">(</span><span class=\"token string\">'appending_data'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#create edge to k</span>\n            <span class=\"token keyword\">if</span> data <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n                graph<span class=\"token punctuation\">.</span>add_node<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span><span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#node_list.append((data, {\"type\" : data}))</span>\n                graph<span class=\"token punctuation\">.</span>add_edge<span class=\"token punctuation\">(</span>previous_k<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> relationship <span class=\"token operator\">=</span> <span class=\"token string\">\"is\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> previous_k<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#edge_list.append((previous_k ,data,{'relationship': \"is\"}, {'type' : data}))</span>\n                <span class=\"token comment\">#edge_list.append((root,data))</span>\n\n    <span class=\"token comment\">#flatten(hierarchak)_dict)</span>\n        <span class=\"token keyword\">return</span> graph \n\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">node_runner</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">,</span>graph<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        \n        node_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        edge_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#root = item['title']</span>\n            graph <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>node_gen_2<span class=\"token punctuation\">(</span>data <span class=\"token operator\">=</span> item<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span> graph <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(edge_list)</span>\n        <span class=\"token keyword\">return</span> graph\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">node_generator</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> root <span class=\"token operator\">=</span><span class=\"token string\">'title_testing'</span><span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> edge_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span> v <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">and</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> node_list<span class=\"token punctuation\">:</span>\n                    node_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">)</span>\n                    edge_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>root <span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#pprint('passing_value')</span>\n                <span class=\"token comment\">#save k</span>\n                previous_k <span class=\"token operator\">=</span> k\n                previous_edge <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>root <span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>node_generator<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span> previous_k <span class=\"token operator\">=</span> k<span class=\"token punctuation\">,</span> previous_edge <span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">elif</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n                <span class=\"token comment\">#pprint('passing_data')</span>\n\n                self<span class=\"token punctuation\">.</span>node_generator<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">,</span>root <span class=\"token operator\">=</span> root<span class=\"token punctuation\">,</span> node_list <span class=\"token operator\">=</span> node_list<span class=\"token punctuation\">,</span>edge_list <span class=\"token operator\">=</span> edge_list<span class=\"token punctuation\">,</span>previous_k <span class=\"token operator\">=</span> previous_k<span class=\"token punctuation\">,</span> previous_edge<span class=\"token operator\">=</span> previous_edge<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#create_edge to k</span>\n\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#this item is no longer a dictionary or list</span>\n            pprint<span class=\"token punctuation\">(</span><span class=\"token string\">'appending_data'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#create edge to k</span>\n            <span class=\"token keyword\">if</span> data <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n                node_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n                edge_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>previous_k <span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                edge_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>root<span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">#flatten(hierarchak)_dict)</span>\n        <span class=\"token keyword\">return</span> node_list<span class=\"token punctuation\">,</span> edge_list \n        <span class=\"token comment\">#self.json_graph = self.create_json_graph()</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_json_graph</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#graph = nx.Graph(self.response_json)</span>\n        graph <span class=\"token operator\">=</span> nx<span class=\"token punctuation\">.</span>from_dict_of_dicts<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#graph = json_graph.node_link_graph(self.response_json)</span>\n        nx<span class=\"token punctuation\">.</span>draw<span class=\"token punctuation\">(</span>graph<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> graph\n        \n        <span class=\"token comment\">#self.node_list = self.node_generator`</span>\n\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_search_result_node</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n     \n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>response_json_flat<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span>v <span class=\"token keyword\">in</span> item<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">:</span>\n                    column_string <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>colnum_string<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n                    self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>colnum_string<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>num_columns<span class=\"token punctuation\">)</span>\n                    self<span class=\"token punctuation\">.</span>num_columns <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">continue</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">append_to_data_list</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>rnge<span class=\"token punctuation\">,</span>d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token comment\">#rename to _data_list</span>\n        request_body <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'range'</span><span class=\"token punctuation\">:</span> rnge<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"majorDimension\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"COLUMNS\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"values\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>d<span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> request_body\n        <span class=\"token comment\">#data_list.append(request_body_tmp)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">map_column_to_range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>column_key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        \n        rnge <span class=\"token operator\">=</span> <span class=\"token string\">\"'Sheet1'\"</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"!\"</span> <span class=\"token operator\">+</span> column_key <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> rnge\n                \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">colnum_string</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>num_columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        string <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span>\n        <span class=\"token comment\">#pprint(\"conlum_string\")</span>\n        <span class=\"token comment\">#pprint(num_columns)</span>\n        <span class=\"token keyword\">while</span> num_columns <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            num_columns<span class=\"token punctuation\">,</span> remainder <span class=\"token operator\">=</span> <span class=\"token builtin\">divmod</span><span class=\"token punctuation\">(</span>num_columns <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">26</span><span class=\"token punctuation\">)</span>\n            string <span class=\"token operator\">=</span> <span class=\"token builtin\">chr</span><span class=\"token punctuation\">(</span><span class=\"token number\">65</span> <span class=\"token operator\">+</span> remainder<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> string\n            <span class=\"token comment\">#pprint(string)</span>\n        <span class=\"token keyword\">return</span> string\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">map_columns_to_lookup_table</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        <span class=\"token comment\">#print('first_map_columns_print')</span>\n        <span class=\"token comment\">#num_columns_tmp = self.num_columns</span>\n        <span class=\"token comment\">#pprint(num_columns_tmp)</span>\n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>response_json_flat<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> item<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                num_columns_tmp <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>num_columns\n                <span class=\"token keyword\">if</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">:</span>\n                    <span class=\"token comment\">#print('second_map_Columns_print')</span>\n                    <span class=\"token comment\">#pprint(num_columns_tmp)</span>\n                    self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>colnum_string<span class=\"token punctuation\">(</span>num_columns <span class=\"token operator\">=</span> num_columns_tmp<span class=\"token punctuation\">)</span>\n                    self<span class=\"token punctuation\">.</span>num_columns <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>num_columns <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n       \n                    <span class=\"token comment\">#append range to request... </span>\n                    <span class=\"token comment\">#append collumn to batch lookup</span>\n                \n\n                <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">continue</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">column_request_list_generator</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        request_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> k<span class=\"token punctuation\">,</span>v <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>column_lookup_table<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            rnge <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>map_column_to_range<span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">)</span>\n            request_body <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>append_to_data_list<span class=\"token punctuation\">(</span>rnge<span class=\"token punctuation\">,</span>v<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#pprint(request_body)</span>\n            request_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>request_body<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> request_list\n\n\n\n\n\n        <span class=\"token comment\">#return column_lookup_table</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_next_url</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">[</span><span class=\"token string\">'pagination'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'next'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_search_url</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>query_param<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">,</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        url_sep <span class=\"token operator\">=</span><span class=\"token string\">\"/\"</span>\n        page_param <span class=\"token operator\">=</span> page_param <span class=\"token operator\">+</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        query <span class=\"token operator\">=</span> <span class=\"token string\">\"&amp;\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        query <span class=\"token operator\">=</span> query_param <span class=\"token operator\">+</span> query\n        search_url <span class=\"token operator\">=</span> url_sep<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>query<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(search_url)</span>\n        \n        <span class=\"token keyword\">return</span> search_url\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">say_hello</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        pprint<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>base_url<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">request_data</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        headers <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'User-Agent'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.11 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'</span><span class=\"token punctuation\">,</span>\n                    <span class=\"token string\">'Accept-Encoding'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'identity'</span>\n                <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>search_url<span class=\"token punctuation\">,</span>headers<span class=\"token operator\">=</span>headers<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">response_to_json</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>response<span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">html_parse</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        soup<span class=\"token operator\">=</span>BeautifulSoup<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>response<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">,</span><span class=\"token string\">'lxml'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(soup)</span>\n        <span class=\"token keyword\">return</span> soup\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">flatten_result</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        flat_result_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>response_json<span class=\"token punctuation\">[</span><span class=\"token string\">'results'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            flat_json <span class=\"token operator\">=</span> flatten<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n            flat_result_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>flat_json<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> flat_result_list\n\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">search_result</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>dict_item<span class=\"token punctuation\">,</span>num_columns<span class=\"token punctuation\">,</span>colnum_string<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>key <span class=\"token operator\">=</span> dict_item<span class=\"token punctuation\">.</span>key<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> dict_item<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>column_string <span class=\"token operator\">=</span> colnum_string\n        self<span class=\"token punctuation\">.</span>index <span class=\"token operator\">=</span> num_columns\n        self<span class=\"token punctuation\">.</span><span class=\"token builtin\">range</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>create_column_range_string<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>request_body <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>create_column_request<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_column_request</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        request_body <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'range'</span><span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"majorDimension\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"COLUMNS\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"values\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>self<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> request_body\n\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_column_range_string</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        rnge <span class=\"token operator\">=</span> <span class=\"token string\">\"'Sheet1'\"</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"!\"</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>column_string <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> rnge\n    <span class=\"token keyword\">def</span> <span class=\"token function\">colnum_string</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> num_columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        string <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span>\n        <span class=\"token keyword\">while</span> num_columns <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            num_columns<span class=\"token punctuation\">,</span> remainder <span class=\"token operator\">=</span> <span class=\"token builtin\">divmod</span><span class=\"token punctuation\">(</span>num_columns <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">26</span><span class=\"token punctuation\">)</span>\n            string <span class=\"token operator\">=</span> <span class=\"token builtin\">chr</span><span class=\"token punctuation\">(</span><span class=\"token number\">65</span> <span class=\"token operator\">+</span> remainder<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> string\n        <span class=\"token keyword\">return</span> string\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">google_drive</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>creds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>service <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>get_drive_service<span class=\"token punctuation\">(</span>creds<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        pprint<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello I exist\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_drive_service</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> creds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Shows basic usage of the Drive v3 API.\n        Prints the names and ids of the first 10 files the user has access to.\n        \"\"\"</span>\n        SCOPES <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token comment\">#creds = None</span>\n        <span class=\"token comment\"># The file token.json stores the user's access and refresh tokens, and is</span>\n        <span class=\"token comment\"># created automatically when the authorization flow completes for the first</span>\n        <span class=\"token comment\"># time.</span>\n\n        service <span class=\"token operator\">=</span> build<span class=\"token punctuation\">(</span><span class=\"token string\">'drive'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'v3'</span><span class=\"token punctuation\">,</span> credentials<span class=\"token operator\">=</span>creds<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Call the Drive v3 API</span>\n        results <span class=\"token operator\">=</span> service<span class=\"token punctuation\">.</span>files<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>\n            pageSize<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> fields<span class=\"token operator\">=</span><span class=\"token string\">\"nextPageToken, files(id, name)\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>execute<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        items <span class=\"token operator\">=</span> results<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'files'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> items<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'No files found.'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Files:'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> items<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">u'{0} ({1})'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">[</span><span class=\"token string\">'name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> item<span class=\"token punctuation\">[</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> service\n    \n    \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_folder</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>title<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        drive_service <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>service\n        file_metadata <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'{}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'mimeType'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'application/vnd.google-apps.folder'</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token builtin\">file</span> <span class=\"token operator\">=</span> drive_service<span class=\"token punctuation\">.</span>files<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>body<span class=\"token operator\">=</span>file_metadata<span class=\"token punctuation\">,</span>\n                                            fields<span class=\"token operator\">=</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>execute<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Folder ID: %s'</span> <span class=\"token operator\">%</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">add_spreadsheet_to_folder</span><span class=\"token punctuation\">(</span>self <span class=\"token punctuation\">,</span>folder_id<span class=\"token punctuation\">,</span>title<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        drive_service <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>service\n    \n        file_metadata <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">'name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'{}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>title<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'parents'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>folder_id<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'mimeType'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'application/vnd.google-apps.spreadsheet'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">}</span>\n\n        res <span class=\"token operator\">=</span> drive_service<span class=\"token punctuation\">.</span>files<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>body<span class=\"token operator\">=</span>file_metadata<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>execute<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#print(res)</span>\n\n        <span class=\"token keyword\">return</span> res\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">google_sheet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>creds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>service <span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>get_sheet_service<span class=\"token punctuation\">(</span>creds<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_sheet_service</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>creds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        service <span class=\"token operator\">=</span> build<span class=\"token punctuation\">(</span><span class=\"token string\">'sheets'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'v4'</span><span class=\"token punctuation\">,</span> credentials<span class=\"token operator\">=</span>creds<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> service<span class=\"token punctuation\">.</span>spreadsheets<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">google_creds</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>creds_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        self<span class=\"token punctuation\">.</span>creds <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>get_creds<span class=\"token punctuation\">(</span>creds_path<span class=\"token punctuation\">)</span>\n   \n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_creds</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>creds_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        creds <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        <span class=\"token comment\"># The file token.json stores the user's access and refresh tokens, and is</span>\n        <span class=\"token comment\"># created automatically when the authorization flow completes for the first</span>\n        <span class=\"token comment\"># time.</span>\n        <span class=\"token keyword\">if</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>exists<span class=\"token punctuation\">(</span><span class=\"token string\">'token.json'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            creds <span class=\"token operator\">=</span> Credentials<span class=\"token punctuation\">.</span>from_authorized_user_file<span class=\"token punctuation\">(</span><span class=\"token string\">'token.json'</span><span class=\"token punctuation\">,</span> SCOPES<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># If there are no (valid) credentials available, let the user log in.</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> creds <span class=\"token keyword\">or</span> <span class=\"token keyword\">not</span> creds<span class=\"token punctuation\">.</span>valid<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> creds <span class=\"token keyword\">and</span> creds<span class=\"token punctuation\">.</span>expired <span class=\"token keyword\">and</span> creds<span class=\"token punctuation\">.</span>refresh_token<span class=\"token punctuation\">:</span>\n                creds<span class=\"token punctuation\">.</span>refresh<span class=\"token punctuation\">(</span>Request<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"no creds\"</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                creds <span class=\"token operator\">=</span> service_account<span class=\"token punctuation\">.</span>Credentials<span class=\"token punctuation\">.</span>from_service_account_file<span class=\"token punctuation\">(</span>creds_path<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\">#creds = ServiceAccountCredentials.from_json_keyfile_name('add_json_file_here.json', SCOPES)</span>\n                <span class=\"token comment\">#flow = InstalledAppFlow.from_client_secrets_file(</span>\n                <span class=\"token comment\">#    'credentials.json', SCOPES)</span>\n                <span class=\"token comment\">#creds = flow.run_local_server(port=0)</span>\n            <span class=\"token comment\"># Save the credentials for the next run</span>\n            <span class=\"token comment\">#with open('token.json', 'w') as token:</span>\n            <span class=\"token comment\">#    token.write(creds.to_json())</span>\n        <span class=\"token keyword\">return</span> creds\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">config</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#self.yaml_stream = file(\"config.yaml\", 'r')</span>\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>load_config<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">load_config</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>file_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#print(\"test\")</span>\n        stream <span class=\"token operator\">=</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span>\n        data <span class=\"token operator\">=</span> yaml<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>stream<span class=\"token punctuation\">,</span>Loader <span class=\"token operator\">=</span> Loader<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#pprint(data)</span>\n        <span class=\"token keyword\">return</span> data\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_google_credentials_object</span><span class=\"token punctuation\">(</span>creds_path <span class=\"token operator\">=</span> <span class=\"token string\">'credentials.json'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    google_credentials_object <span class=\"token operator\">=</span> google_creds<span class=\"token punctuation\">(</span>creds_path<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> google_credentials_object\n    \n<span class=\"token keyword\">def</span> <span class=\"token function\">create_config_object</span><span class=\"token punctuation\">(</span>file_path <span class=\"token operator\">=</span> <span class=\"token string\">'config.yaml'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    config_object <span class=\"token operator\">=</span> config<span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> config_object\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">search_result_generator</span><span class=\"token punctuation\">(</span>condition <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#column_lookup_table = {}</span>\n    <span class=\"token comment\">#pprint(num_columns)</span>\n    page_num <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    column_lookup_table <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">while</span> condition <span class=\"token operator\">==</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#pprint(num_columns)</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">61</span><span class=\"token punctuation\">)</span>\n        search_results_page_object <span class=\"token operator\">=</span> create_search_results_page_object<span class=\"token punctuation\">(</span>page_num <span class=\"token operator\">=</span> page_num<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> search_results_page_object<span class=\"token punctuation\">.</span>next_url <span class=\"token operator\">!=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            condition <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n            page_num <span class=\"token operator\">=</span> page_num <span class=\"token operator\">+</span> <span class=\"token number\">1</span>            \n            <span class=\"token keyword\">yield</span> <span class=\"token punctuation\">(</span>search_results_page_object<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            condition <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n            <span class=\"token keyword\">yield</span> <span class=\"token punctuation\">(</span>search_results_page_object<span class=\"token punctuation\">)</span>\n        \n<span class=\"token keyword\">def</span> <span class=\"token function\">create_search_results_page_object</span><span class=\"token punctuation\">(</span>base_url <span class=\"token operator\">=</span> <span class=\"token string\">\"https://www.loc.gov/collections\"</span><span class=\"token punctuation\">,</span>collection <span class=\"token operator\">=</span> <span class=\"token string\">\"united-states-reports\"</span><span class=\"token punctuation\">,</span>json_parameter <span class=\"token operator\">=</span> <span class=\"token string\">\"fo=json\"</span><span class=\"token punctuation\">,</span>results_per_page <span class=\"token operator\">=</span> <span class=\"token string\">\"c=70\"</span><span class=\"token punctuation\">,</span>query_param <span class=\"token operator\">=</span> <span class=\"token string\">\"?\"</span><span class=\"token punctuation\">,</span>page_param <span class=\"token operator\">=</span><span class=\"token string\">\"sp=\"</span><span class=\"token punctuation\">,</span>page_num <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#search = search_results(base_url,collection,json_parameter,results_per_page,query_param,page_param,page_num)</span>\n    <span class=\"token comment\">#pprint(search.search_url)</span>\n    <span class=\"token comment\">#pprint(num_columns)</span>\n    <span class=\"token keyword\">return</span> search_results_page<span class=\"token punctuation\">(</span>base_url<span class=\"token punctuation\">,</span>collection<span class=\"token punctuation\">,</span>json_parameter<span class=\"token punctuation\">,</span>results_per_page<span class=\"token punctuation\">,</span>query_param<span class=\"token punctuation\">,</span>page_param<span class=\"token punctuation\">,</span>page_num<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_google_drive_object</span><span class=\"token punctuation\">(</span>google_creds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    drive_service_object <span class=\"token operator\">=</span> google_drive<span class=\"token punctuation\">(</span>google_creds<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> drive_service_object\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_google_sheet_object</span><span class=\"token punctuation\">(</span>google_creds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    sheet_service_object <span class=\"token operator\">=</span> google_sheet<span class=\"token punctuation\">(</span>google_creds<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> sheet_service_object\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_new_google_sheet</span><span class=\"token punctuation\">(</span>google_drive_object<span class=\"token punctuation\">,</span>folder_id<span class=\"token punctuation\">,</span>title<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    sheet_meta_data <span class=\"token operator\">=</span> google_drive_object<span class=\"token punctuation\">.</span>add_spreadsheet_to_folder<span class=\"token punctuation\">(</span>folder_id<span class=\"token punctuation\">,</span> title<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> sheet_meta_data\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">flatten_result</span><span class=\"token punctuation\">(</span>result_json<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    flat_json <span class=\"token operator\">=</span> flatten<span class=\"token punctuation\">(</span>result_json<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> flat_json\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">write_last_page_num</span><span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'last_page_num.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n        f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    tracemalloc<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#rate_limiter = RateLimiter(max_calls=1, period=60)</span>\n    <span class=\"token comment\">#cd to output</span>\n    <span class=\"token comment\">#result = create_search_results_page_object()</span>\n    <span class=\"token comment\">#with cd(\"output\"):</span>\n    <span class=\"token comment\">#    result.write_to_file(data = result.dict_of_dicts, file_num = 1)</span>\n\n    <span class=\"token keyword\">for</span> obj <span class=\"token keyword\">in</span> search_result_generator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>   \n        page_num <span class=\"token operator\">=</span> obj<span class=\"token punctuation\">.</span>page_num\n        <span class=\"token keyword\">with</span> cd<span class=\"token punctuation\">(</span><span class=\"token string\">\"output_2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\">#print('hahaha')</span>\n            obj<span class=\"token punctuation\">.</span>to_json<span class=\"token punctuation\">(</span>file_num <span class=\"token operator\">=</span> page_num<span class=\"token punctuation\">)</span>\n            <span class=\"token comment\">#obj.write_graphml(file_num= page_num)</span>\n            <span class=\"token comment\">#obj.to_pandas()</span>\n            <span class=\"token comment\">#obj.write_to_file(data = obj.dict_of_dicts, file_num = page_num)</span>\n            <span class=\"token comment\">#obj.to_csv()</span>\n        write_last_page_num<span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"{} Search Results Crawled\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>page_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n    \n    snapshot <span class=\"token operator\">=</span> tracemalloc<span class=\"token punctuation\">.</span>take_snapshot<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    top_stats <span class=\"token operator\">=</span> snapshot<span class=\"token punctuation\">.</span>statistics<span class=\"token punctuation\">(</span><span class=\"token string\">'lineno'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"[ Top 10 ]\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> stat <span class=\"token keyword\">in</span> top_stats<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>stat<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        \n        \n\n    </code></pre></div>","frontmatter":{"title":"Crawling the Library of Congress API","date":"May 16, 2022","description":"Crawl the Library of Congress API to automate your next research project.","imageAlt":"Justin Napolitano","author":"Justin napolitano","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAMAAf/aAAwDAQACEAMQAAABTxTJNBAy/8QAGxAAAwACAwAAAAAAAAAAAAAAAAECAxESEyH/2gAIAQEAAQUCnK2XWzsoXhLOJ//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AUf/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwGK/8QAGhAAAgIDAAAAAAAAAAAAAAAAABEBAiAhMf/aAAgBAQAGPwJ23hLOn//EABoQAAMBAQEBAAAAAAAAAAAAAAABESFBkTH/2gAIAQEAAT8hcODeCJk9HwecxGjS+7o11qCqyD//2gAMAwEAAgADAAAAEHDf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQAR/9oACAEDAQE/ENITf//EABcRAQEBAQAAAAAAAAAAAAAAAAERACH/2gAIAQIBAT8QK7kjLv/EABoQAQADAQEBAAAAAAAAAAAAAAEAESExgfD/2gAIAQEAAT8QKxJTYWz7kxIBrXUahSMpwuEBXTTeZyDuoLr2X0hHk//Z"},"images":{"fallback":{"src":"/static/794367035c6138c43c02f27abdaa40e6/20b93/post-image.jpg","srcSet":"/static/794367035c6138c43c02f27abdaa40e6/6cce3/post-image.jpg 750w,\n/static/794367035c6138c43c02f27abdaa40e6/20b93/post-image.jpg 800w","sizes":"100vw"},"sources":[{"srcSet":"/static/794367035c6138c43c02f27abdaa40e6/b56ea/post-image.avif 750w,\n/static/794367035c6138c43c02f27abdaa40e6/ba9bc/post-image.avif 800w","type":"image/avif","sizes":"100vw"},{"srcSet":"/static/794367035c6138c43c02f27abdaa40e6/d2a19/post-image.webp 750w,\n/static/794367035c6138c43c02f27abdaa40e6/56f2e/post-image.webp 800w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6675}}}}},"previous":{"fields":{"slug":"/carbon-shipping-projections/"},"frontmatter":{"title":"Monte Carlo Projection of the Annual Cost of Shipping Carbon from Europe to the United States"}},"next":{"fields":{"slug":"/neo4j_integration/"},"frontmatter":{"title":"Integrating JSON data to your Neo4j Stack"}}},"pageContext":{"id":"c37f105a-dd41-5f18-9dd3-df41400006f2","previousPostId":"e2dd9126-dada-5be9-93d4-aa45f3f139ac","nextPostId":"e6eb87b5-8ec8-5ad2-923d-971a6aa024ae"}},
    "staticQueryHashes": ["2841359383","3257411868"]}